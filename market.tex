% http://arxiv.org/pdf/1609.01037.pdf
% and even allow over-specification (a.k.a. improper learning), in the sense
% that we allow the learning algorithm to output a predictor which is possibly larger and more complex than
% the target function (this technique increases the power of the learner, and was shown to make the learning
% problem easier in theory and in practice [17, 20, 21]). Even under such favorable conditions, we show the
% following
% [17] Roi Livni, Shai Shalev-Shwartz, and Ohad Shamir. On the computational efficiency of training neural
% networks. In Advances in Neural Information Processing Systems, pages 855â863, 2014.
% 20 Itay Safran and Ohad Shamir. On the quality of the initial basin in overspecified neural networks. In
% ICML, 2016.
% 21 Daniel Soudry and Yair Carmon. No bad local minima: Data independent training error guarantees for
% multilayer neural networks. arXiv preprint arXiv:1605.08361, 2016.


%!TEX root = main.tex
% optimal decision elicitiation algorithm

Consider a subject facing a decision, who wishes to incentivise multiple experts in providing advice so as to pick a decision that maximizes the rewards the subject receives.
Experts do not have intrinsic interest in the action the subject chooses or actually takes, nor do they face any costs in aquiring their signals.

One natural way to attempt to do is by applying the machinery of prediction markets based on sequentially shared proper scoring rules to the expected reward, conditional on the action. 
A challenge that presents itself is how to settle the markets for the reward conditional on the action which is not taken.
One natural approach is to void the trades in the markets for these actions, this being the originally proposed mechanism in this line of work \cite{hanson2002decision}, and only settling the markets where actions are taken.
While natural, this is not incentive compatible, even in the weakest myopic sense \cite{othman2010decision}. 
More generally, any sequential proper scoring rule based mechanism that is incentive compatible for the experts is incompatible with maintaining the subject's freedom to select the action that appears optimal ex-post \cite{othman2010decision,  chen2014eliciting}, that is using the max decision rule (in the decision markets literature nomenclature, and ex-post incentive compatible in the mechanism design literature). 

%TODO: garrett says more clear explanation. make explicit pointer to background section, and make paragraph of sentence.
The core of the problem which emerges upon using the machinery of prediction markets in the decision setting is that at the point where the mechanism has a correct belief over the optimal action but not the other action, a expert can profit by changing expected rewards to make the optimal action appear worse than an action for which the conditional expected reward can be corrected, thus failing even myopic incentive compatibility (as this holds for the last expert to interact with the market maker).
The guiding design criterion in this work is to restrict as little as possible the decision that the subject must take (maximizing their freedom) while still providing good incentives to the experts. No previous mechanisms analyzed in the literature truthfully aggregate arbitrary signals over many experts in BNE. 

We first focus on a direct efficient mechanism in the style of the VCG mechanism. Experts directly report their signals to the mechanism, which then uses them to compute the optimal action given the prior output to the subject. This requires the experts and the mechanism having access to a common prior, over the joint probabilities of the rewards, true signals, the output action and the response of the subject to a given output of the mechanism. There is an efficient BNE that aggregates all information over $N$ experts, unlike the case in previous mechanisms in the literature.
We then analyze a simple bid based variation of the mechanism, and provide sufficient conditions on the signal structures where information can be fully aggregated; we further show that these conditions are sufficient to make truthfulness dominant incentive compatible.  
We end the chapter by considering mechanisms that do not make use of a common prior (we still need to assume the common prior for the agents to have well defined BNE, but we seek mechanisms that need not use it). We show that natural mechanisms to do this in the one shot case have the undesirable property of rewarding experts who do not bring valuable information to the decision.

\section{Model}


% define a and c and r beforehand, pointer to notation section
As before $c$ is the action chosen by the mechanism, $a$ is the action that the subject actually carries out, and $r$ is the reward received by the subject, which is in ${0,1}$. An expert $i$ receives signal $s_i$, we refer to $s$ as a given set of signal for all experts, and we denote by $S$ the set of all possible experts' signals.
We use $P$ to denote the a priori joint probability distribution over $(r,a,c,s)$, and expectations are taken in relation to said prior.
We use $Pr$ to denote the probability of a given event.
\NDP{Does this make sense? should i just use Pr for both?}
We consider a single subject with access to $K$ possible choices, and to $N$ experts. We denote a generic expert by $i$, and each have access to some signals $s_i$ which are potentially informative about $\expec[r|a,c,s]$. The set of possible signals and actions are both finite.

%TODO note limit of this that agent isnt considering what the mechanism is in deciding how to map c to a.

When notating expectation in the mechanisms with common priors, we suppress the variables that are being marginalized over in general, so for example $\expec[r|c,s]$ is the expected reward conditional on a given set of signals to the experts and choice of action by the mechanism, where we marginalize over the actually taken action $a$:

\[
\expec[r|c,s] = \sum_{a \in A} Pr(r|c,a,s) \times P(a|c,s) 
\]


To map to the mechanism design literature the $P$ would be over states of the world in $\Omega$ and each state of the world consists of an agent type and the signals of each expert in that state of the world. The agent type consists of a complier probability and action outcome, which equates to rewards in our notation.

%TODO either pin the Omega

% DEFINITION 2: Security X is non-separable under partition structure Î  if there exist distribution P on the underlying state space Î© and value v â R such that:
% (i) P(Ï) is positive on at least one state Ï in which X(Ï) Ìž= v; (ii) For every player i and every state Ï with P(Ï) > 0,
% ô°
% P(Ïâ²)X(Ïâ²)
% EP X|Î i(Ï) â¡ ô° P(Ïâ²) =vô°·
% ô°¥ ô°Š Ïâ²âÎ i(Ï)
% Ïâ² âÎ i (Ï)
% ï¿ŒOtherwise, security X is separable.


A direct mechanism announces a payment rule $p_i(\hat{s}, c,a,r)$, with $p_i$ being the payment to expert $i$, with $\hat{s}$ being the reported signals. 
Each expert $i$ receives their signals $s_i$ and makes a report $\hat{s}_i$ to the mechanism, which then outputs a chosen action based on those reports.
The subject observes the action chosen by the mechanism $c$, and takes a (potentially different) action $a$. A reward $r$ is observed, and the mechanism makes the corresponding payments.

We denote by $c^{*}_s$ the reward maximizing choice given the true signals $s$.
An expert $i$'s report is truthful when $\hat{s}_i=s_i$. A mechanism is incentive compatible when truthful reports maximize the payment experts receive and this holds for all experts. This can occur in dominant strategies or in a Bayesian Nash Equilibrium (BNE).  We seek truthful and efficient mechanisms, that is $c^{*} = \hat{c}$ for all possible signals.






\subsection{Freedom and Limits to Defiance}

If we consider subjects with potentially unrestricted freedom, i.e. subjects are not necessarily expected reward maximizers nor always-takers, then the mechanism is not necessarily truthful, even for a single expert. 

\begin{eg}[Total freedom yields bad incentives for a single expert]
	Consider a subject that has a prejudice in favor of treatment A, and so will take it unless the expected reward of treatment B is more than 10 utils higher. Consider an expert with access to a signal which is an unbiased estimate of the rewards over both actions, who receives a signal that B reward is higher by 9 utils. The expert is strictly better off reporting that his signal has B as more than 10 better.
\end{eg}

% That is, in such situations misdirection is required to achieve efficiency. More pathological cases can lead to more severe problems:% \begin{eg}[subjects who defy experts yield perverse incentives]
% 	More generically we can consider of an agent who does the oposite of what maximizes reward (the min decision rule), this creates incentives for experts in equilibrium to flip the ordering that some of their signals imply (flipping the full ordering is not a equilibria since the subject can reverse it).
% \end{eg}


It is clear that such preference structures on the part of the subjects makes attaining both truthfulness and efficiency impossible. 
Thus, it appears that providing unrestricted freedom in the broadest sense to subjects makes efficient incentive compatible mechanisms unattainable in general.
One restriction on subjects freedom that is sufficient to allow truthful mechanisms is: 

\begin{defn}[maximizers or always takers]: assuming that all subjects are either utility maximizers (compliers under a efficient mechanism) or have some action they will take irrespective of the reports of the experts (always takers or never takers in the binary setting). 
\end{defn}

Note for example that in the canonical two treatment setting this is equivalent to the usual no defiers assumption.
This preserves substantial freedom; it is not required of the subject to know ex ante that they will comply, their realization of the always taker type could come after the mechanism has been run and before the action is taken. 
While this is a strong assumption to make, it is still substantially weaker than requiring subjects to follow ex post dominated actions with a given positive probability (and since the payments are dependent on this probability this needs to be followed precisely), which is what is required in the MSR and void type mechanisms.


% This condition can be somewhat relaxed,  since the needed property it implies is that the mechanism choosing an action with higher expected reward if actually carried out leads to the expected reward conditional on the chosen action to be higher. Formally a sufficient condition is:

% \[
% \expec[ ^{*}|c_i]  \geq \expec[ r^{*}|c_j] \text{ if }\expec[ ^{*}|a_i]  \geq \expec[ r^{*}|a_j]  \forall j \neq i \in K
% \]

%TODO
%There is some extra flexibility more than no defiers which we should use, for example differential compliance rates for different actions, the mechanisms selects the action that most raises the reward not the one who has the highest reward (for example an action that has the second highest reward but 1\% noncompliance might be chosen instead of one  that has 99\% noncompliance and the highest reward. No defiers buys us the extra part that chosen is the highest reward action, so makes life easier for the subject (if the noncompliance depended on the signals the expert receives a utility maximizing decision maker would have to consider other decision markets noncomplaince characteristics in the prior before deciding how to interpret the chosen action; this removes such ambiguities and doesn't seem to loose too much generality)


% \subsection{Interpreting bids \& Recomending their Wishes}

% So far we have treated one space of actions $A$ for both $c$ and $a$. We now note that it may be advantageous for the mechanism to have elements in $A$ that are not available in $a$. In particular a \emph{as you wish} choice $c$ byt he algorithm, when the expert believes that hecannot add value relative to the private information of the subject. While in the signal case with common priors the signal report of the subject can be added initially (and used as part of the prior that sets the benchmark reward that is discounted from the realized reward in setting payments), there is no natural way to do this in the more realitic setting whre the subject and experts do not share a prior.   

%\subsection{Interpreting bids}


% TODO:
% \begin{eg}[IID signals for experts]\label{eg:iid-ex}
% 	Let there be two experts, two actions ${\text{treatment},\text{control}}$ each which rewards with abernoulli draws with probabilities either $\alpha,1-\alpha$ or  $1-\alpha,\alpha$. Let the prior over $\alpha$ be a beta distribution
% \end{eg}

% %The bids reflect the expected value of the mechanism choosing a particular action, not of that action being taken. \DBA{I'm confused. In previous section, ``each expert knows the exact outcome conditonal on one action'', and now its conditional on action being chosen, not taken. These sentences sentences seem to be at odds.} Example: if half are allways takers, the bid effectively waters down the true effect by half.

% \DBA{So the bids made by experts depend on the expert's model of the subject's behavior?}
% \NDP{correct, is this clear now form the text?}
%further, due to the winners curse, it is the expected effect conditional on having won the auction. 
%\DBA{can you write down how expected conditional on having won is computed?}

%\DBA{At this point, the interpretation of the bid has been qualified twice, and I'm lost}

%\subsection{A sufficient separability condition for efficiency}

%if each expert knows the value of a action the MSR and Void mechanism in the style of Hanson fail to be myopically incentive compatible when agents always follow the action whose price is maximal in the market (\cite{othman2010decision})



% \subsection{Noncompliance and Incentive Compatibility}

% A natural question that arrises is how to handle the case where the action that is optimal given the reports (the chosen action under perfect compliance) is not the actual action taken by the subject. 
% The three natural strategies are available:

% \begin{itemize}
% \item make payments irrespective.. 
% \item make the payments to the experts but do not require the experts to make the payents.
% \item make no payment, and require no payment.
% \end{itemize}

% \NDP{TODO: formalize}
%  Only the first is incentive compatible. 

 % Sketch: a crucial property is that w separate bids and reports, this lets the reports be truthful while the bids are shaded (as is standard in common value seccond price auction). Further, it means that noncompliance (given the no defiers assumption) 
% \DBA{maybe I'm missing something. But if the subject has a strong tendency to pick low-reward actions, then the experts are disincentivized from providing any advice at all, since they will likely receive negative payouts}
% \NDP{The prior is over the noncompliance (what you are terming it the tendency to pick low actions here) }
% If we do not require the payment, it can incentivize experts to report in such a way as to encourage non-compliance, since this would increase their payout. 
% \DBA{example}


% If we void the payment completely this can have the oposite effect, biasing experts away from reporting the \DBA{Is this paragraph dependent on agent's having a model of the subject's noncompliance? E.g. If subject's noncompliance is random (ignore advice with probability $p$ and then pick action uniformly), are the second and third options incentive compatible?}
% \NDP{yes it is}


% % 
% For a cancer example; the chemiotherapy specialist might explain the likely side effects conditional on their knowledge of the specifics of the patient\footnote{ (the rapidly dropping cost of sequencing a genome means this) }without needing to understand the relative value the patient places on discomfort relative to life lengthening, while the surgeon might explain the risks he foresees in the surgury for that patient, without needing to udnerstand the risk aversion of the patient which would be necesary for calculating their utility.

% the subject (oracle style) can then be queried for their chosen action and expected utility for different subsets of the signals (for every expert we need to query what the action (and the expected payoff) would be without that experts signal having been reported)

% contrast the information structure in the cancer example and its non separability 

% % While some, such as \cite{geanakoplos1982we} argue that the complementary signals example situation is artificial, \cite{ostrovsky2012information} note that it is not degenerate in the sense that 





\section{Simple Mechanisms and Fundamental Limits}

%motivate why this example.
Consider the following adaptation of the classic complementary knowledge example from the full supervised setting, which originates in \cite{geanakoplos1982we}, to the bandit setting:

\begin{eg}[Fully Complementary Experts]\label{eg:comp-ex}
	Let there be two experts, two actions ${\text{treatment},\text{control}}$ and four equal probability states of the world, ${A,B,C,D}$, with payoffs to the actions correspondingly as ${(0,5,1),(0.5,0),(0,0.5),(1,0.5)}$. Let one expert observe that they are in either ${A,B}$ or ${C,D}$ and the other ${B,C}$ or ${A,D}$. A uniform random strategy achieves an expected value of $0.5$. An optimal strategy with access to a single expert's signal (either one) also achieves a value of $0.5$. Using both signals an optimal strategy achieves reward of $1$. Thus the VCG payments are $0.5$ to each expert when they both truthfully report, and this is an equilibrium. The mechanism improves the subject's welfare by $0.5$ while making $1$ in total payments to the experts. 
\end{eg}

In the example, by construction, it is common knowledge that each player's expectation of the value of the reward conditional on either action is $0.5$, even though it is also common knowledge that the realized value of the reward conditional on one of the actions is not $0.5$, and that the traders' pooled information would be sufficient to determine the optimal action. 
Thus, even if the traders repeatedly and truthfully announce their posteriors, as in \cite{geanakoplos1982we}, they will never learn the true optimal arm. 
This illustrates a fundamental limit to the information that can be aggregated by market like mechanisms that rely on prices for information transmission (indirect mechanisms) relative to what could be known if the signals themselves were aggregated. 
It is worth noting at this point that market scoring rule based mechanisms are one form of such indirect mechanism.


We say a expert is useless if knowing their signal would not change the optimal chosen action for any possible set of other experts' signals. More formally,

\begin{defn}[Useless Expert]\label{defn:useless}
	An expert $i$ is \emph{useless} if $\forall s  \in S c^{*}_{s_{-i}} = c^{*}{s}$.
\end{defn}

A particular concern with a mechanism that attracts entry by useless experts, is that while there is no possible upside to them, misreport can still lower reports.

\begin{defn}[Harmless Expert]\label{defn:harmless}
	An expert $i$ is \emph{harmless} if $\forall s \in S \text{ and }\forall \hat{s}_i s c^{*}_{s_{-i}} = c^{*}{s_{-i} \cup \hat{s}_i}$.
\end{defn}

While all \emph{harmless} experts are \emph{useless}, the converse is not the case. To see an intuition for this, consider a signal that implies no change to the prior, and a expert who only observes such a signal, but this is not known a priori. While the expert is clearly \emph{useless}, if he reports truthfully he never adds information; he is not \emph{harmless} in that a misreport could potentially lead to a change in the posterior that changes the chosen action away from the optimal.
The robustness of a mechanism that attracts entry (by having positive expectation) of \emph{useless} but not necessarily \emph{harmless} experts is doubtful.

\begin{defn}[pivotal experts reports]\label{defn:pivotal}
Given a mechanism and reports $\hat{s}_{-i}$, we say an expert $i$ report is \emph{pivotal} if their report $\hat{s}_i$ can change the chosen action $c$.
\end{defn}


\subsection{A Simple Direct Reward Sharing Mechanism}

%structure, mechanism , advantages, disadvantages, maybe a list. deinfe first discuss later

Let us first consider a very basic direct mechanism, which will help us understand the model and the limitations that are imposed by the subject's freedom. 
Perhaps the simplest class of mechanisms is based around the idea of sharing the rewards from the taken action with the experts. For the simple expert case this is mentioned by \cite{othman2010decision}, but the idea also extends to the multiple experts case. 

A simple mechanism that is strictly (if the signal is informative) incentive compatible (in equilibrium) for an expert to reveal their signal when subjects are utility maximizers is to give all experts a share of the reward. Equivalently (in expectation), run a lottery after the reports are submitted that assigns a share of the reward to the expert that wins.
In this case the payment rule is invariant to the reports, and defined as $\pi_i  = (\alpha / N ) r $ with $\alpha < 1$. Note that we are not defining the payment rule to be conditional on the subject's actual action in any way. % In particular, it might naively seem appropiate to only give the share when the chosen action is the actual action carried out. 

This reward sharing mechanism is problematic in a pair of ways. It makes positive payouts to \emph{useless} experts; a corollary of this is that the entry of useless experts reduces the payment received by valuable ones or the budget needed by the mechanism. It also requires that the mechanism has access to the common prior, which is for many applications highly unrealistic. 
As we will see in the next section, either of these, through not both, is avoidable in our setting for efficient mechanisms with unrestricted information structures.


\subsection{Scoring Rule and Void Decision Market Mechanisms}

%not clear; the literature is way too specific, make the two different problems the mechanism has clearer

A somewhat more complicated mechanism is to attempt to use the machine of sequential proper scoring rule based market makers to predict the rewards contingent on choosing each possible action. The market for the chosen action can then be settled in the standard manner, and the other markets voided. 
We term these Scoring-rule and Void Decision Market Mechanisms (SVDM). The basic idea is to use a sequentially shared proper scoring rule to run a prediction market for the value of the reward conditional on each possible action, and to void the markets for the non-chosen actions.  

Theorem 1 of \cite{othman2010decision} states: there does not exist any strictly proper scoring rule/deterministic decision rule pair.
Since in general maximizing the subject's utility requires a deterministic decision rule from a set of reports to the chosen action, this rules out efficient mechanisms based on strictly proper scoring rules. 
It is worth noting that the above holds for even a single expert, precisely the setting under full supervision for which strictly proper scoring rules were introduced. 
For example if the starting price of the optimal actions market is correct initially but for a suboptimal action is not, the expert profits by lowering the optimal action's price (thus forcing the deterministic decision rule to not pick it) while raising the price to the correct value of the suboptimal choice. 

More generally, an immediate corollary to a theorem X of \cite{chen2014eliciting} states that randomized decision rules with full support are necessary for incentive compatible SVDM mechanisms.
Note that this implies all the problems of the max decision rule apply, for example, to a Thompson style randomized decision rule, since they can still be manipulated not to have full support over the action by a sufficiently bad report.

If a subject is free to either maximize their expected utility at decision time (and lacks a credible commitment device beforehand, or wishes to maintain its freedom) then a SRDM is not Incentive Compatible for them. Further, the cost of making the probabilities of dominated actions small is to make the payments that are contingent on when they are taken proportionally larger.
Beyond the reduction in freedom from the pre-commitment to randomization with full support, this also rules out \emph{efficiency}, since by definition, if actions known to be dominated are played with positive probability, the mechanism is not maximizing reward with its choice of action.
 
 \DBA{i guess you can get as close as you like to maximizing \emph{expected} reward, but nevertheless deviate by arbitrarily large amounts from the best reward, with low probability. Worth talking a bit about rewards in expectation and rewards with high probability and rewards with (whatever measure is appropriate here).}
\NDP{As you make the deviation from optimality go to zero the budget needed for a risk neutral agent to participate goes to infinity and even allmost risk neutral agents will drop out. The reason for this is that the multiplier on the suboptimal action has to increase to compensate for its lower probability.  }



A further limitation of such methods is inherited from the prediction markets and more generally from posterior announcement games and their generalizations as analyzed in \cite{ostrovsky2012information}: fully complementary signals between two experts are not aggregated. In particular, for such mechanisms to aggregate information in the full supervision case, the information structures must result in the traded asset satisfying a full separability condition. The latter is not satisfied even in the full supervision version of complementary signals, nor in our bandit supervision adaptation of this in Example~



\section{A Direct Mechanism for Efficient Optimal Choice Elicitation}

Consider a VCG-style mechanism for the optimal decision elicitation problem. 
To the best of our knowledge, this is the first proposed mechanism for one shot optimal decision elicitation that achieves efficiency and does not require payments to useless experts.
%Edit the longass thing into coherent.
This mechanism is VCG-style as it is direct, efficient, and compensates subjects for the externality their signal has on the other agents.
On the other hand, since the agents do not have private values over the choice, it is not a VCG mechanism, which will prove important in the next section.
Our use of received payoff instead of expected payoff avoids the use of counterfactuals that use the signal reported by the agent itself, which enables the mechanisms to be truthful in equilibrium.
All agents and the mechanism have a common prior that gives a proper prior probability distribution of rewards over all possible signals, chosen actions, and actual actions.

\begin{mech}\label{mech:vcg-style}[VCG-style Mechanism]


%$\hat{S}_{-i} = \bigcup \hat{s}_j  \forall j \neq i \in N $ then the expected reward given the others reports is:

For each expert $i$, compute the optimal action to choose without using that expert's report (i.e. marginalizing over the prior on expert $i$'s signal); denote this action $\hat{c}_{-i}$ and its expected reward as: $\expec[\hat{r}_{-i}] = \expec[ r| \hat{c}_{-i}, \hat{s}_{-i}] $


The payment rule is announced as follows:

\[
    \pi_i = 
\begin{cases}
    r - \expec[\hat{r}_{-i}] ,& \text{if } \hat{c}_{-i} \neq c\\
    0,              & \text{otherwise}
\end{cases}
\]

%

Each expert reports their signal, the mechanism calculates the action that maximizes the reward $c$, and chooses it. After observing the actual action taken $a$ and its reward $r$, the corresponding payments are made; this concludes the mechanism.

\end{mech}


Conditional on the action taken, the payments do not depend on the reported signal of agent $i$.
That is, $i$ only affects experts received payments with their report via the choice of action. 

Removing the if and rewarding experts unconditionally results in an increase in the variance of payments but does not change the expectation, since if the action is unchanged and under the assumption the prior is correct, its expected reward must be zero as $\expec[\hat{r}_{-i}] = \expec[r|P,c]$. 
The expected reward in the case when all signals are used and in the case when only the other agents' signals are used has to be equal if the same action is being taken in both: that is, the agent report is not pivotal. 
Thus the mechanism and its properties still hold under the siplified mechanism, given risk neutral experts. 


\begin{lem}\label{lem:affect}
	The only way an expert's report affects their payments in the VCG-style Mechanism is via the chosen action.
\end{lem}

\begin{proof}
There are two terms in the expression for the payment rule $\pi_i$: the received reward $r$ and expected reward $\expec[\hat{r}_{-i}]$, given the counterfactual that expert $i$ is ignored. 
The first term is the reward received after executing the chosen action, and therefore clearly only depends on the chosen action. 
The second term is explicitly constructed so as not to use the report by expert $i$. 
\end{proof}


%TODO: be more precise about what we mean by same signal
\begin{prop}[redundant experts]
	When two or more experts report the same signal, in the revelation BNE they both receive payoff zero. 
\end{prop}

\begin{proof}
	Given the other expert's reports, it is not possible for the same signal to cause different actions, so we always end up in the 0 payment case.
\end{proof}


\begin{prop}
	An \emph{useless} expert cannot profit from participation in a VCG-style Mechanism.
\end{prop}

\begin{proof}
	This is immediate from how the payment rule and useless experts are defined, since there is no report $\hat{s}_i$ that leads to a choice of $c$ which improves the expected value of $r$, and that is all that can lead to expected positive payoffs.
\end{proof}

%TODO pin down useless more formally still

\subsection{Incentive Compatible and Efficient}

\begin{thm}[Bayes-Nash Incentive Compatibility]
	For a VCG-style Mechanism and any information structure, a Bayes Nash Equilibrium exists where all experts truthfully report their signals.
\end{thm}

There is an equilibrium where all experts maximize their payment by maximizing the probability that the action with the highest reward is taken when subjects are utility maximizers; if all other reports are truthful, then the optimal choice is made when the report of an agent is also truthful.
%TODO: add pointer to no defiers.

\begin{proof}
For a given expert $i$, let all other experts truthfully report their signals. By Lemma~\ref{lem:affect}, the only effect an expert has on their payment is via their effect on the chosen action $c$. Given all other experts are truthful, it follows by the definition of Mechanism~\ref{mech:vcg-style} that if expert $i$ is also truthful then the mechanism will select the $c$ that maximizes the expected $r$, thus maximizing the expert $i$'s reward. Truthfulness is therefore a Bayesian Nash equilibrium.
\end{proof}


\subsection{Scaling Payments and Rational Entry}

The mechanism however leads to a potentially negative expectation if subjects are to compensate the experts via the mechanism.  
That is, the payments can be more than the value of the improvement in the reward that the mechanism creates. For example, in Example~\ref{eg:comp-ex} the payments are double the payments. In these situations it is not rational for the subject to enter the mechanism.

%EXPLAIN that VCG mechanism gets an extra degree of freedom, define alpha first

As presented, the VCG-style direct mechanism can have higher payments than the benefits it provides in terms of higher rewards (if there are states of the world with sufficiently high reward differentials and a sufficiently large number of experts with complementary signals). Hence, the subject might be better off not participating \emph{a priori}. Here we introduce a variation on the mechanism that re-scales payments using the prior so a subject \emph{a priori} wishes to participate in the mechanism. The mechanism takes advantage of two observations. Firstly, one can set $\alpha$ prior to receiving signals from experts based on the prior. Secondly, by Lemma~\ref{lem:affect} experts do not care about the chosen action beyond how it affects their payments. 

The second observation does not hold in standard VCG mechanisms: if experts cared about the action, they would need to be compensated exactly for their externality. While this doesn't make an explicit appearance in the proof, it is the reason why we can scale the payments to alter the budget in a way that VCG mechanisms cannot: a change in the allocation that leaves payments unchanged alters the utility of agents in the VCG setting but not here, so the payments in the VCG setting have to move to counter-balance this precisely, limiting the freedom with which we can choose them.

\NDP{Explain relation to the  Clarke pivot rule. With the Clarke pivot rule, the total amount paid by the player is: (social welfare of others if i were absent) - (social welfare of others when i is present).
This is exactly the externality of player  i. 

Since the expert can always send a blank report and thus cause no externality, while sending a useful signal in expectation, raises the expected payoff, the experts participation is weakly profitable in expectation. This requires not scaling the payments, in a model where experts signals are costly to the experts, it would lead (in some situations ) to the optimal signlas being raised byt he experts, this is beyond the scope.  }

In the model we have presented, an expert pays no cost when acquiring their signals, and so in the single agent case the payment made by the subject for signals can in principle be arbitrarily close to zero while still incentivizing truthful reports (for example the share of the reward mechanisms achieves this). We now study when payments rules can be scaled to create ex-ante in expectation arbitrarily small expected payments to the experts. As usual, we assume risk neutral experts. 
% loosing garrett here, dont make the thing point to the proof.


Let $\expec[r|c(s)]$ denote the expected reward obtained from choosing the optimal action using all signals if they where reported truthfully, and $\expec[r|c(P)] $ be the expected reward from picking the action using only the prior and no signals. Thus $\expec[r|c(S)] - \expec[r|c(P)] $ is the expected surplus from using the information in the truthful equilibrium of the mechanism relative to using only the priors. For an efficient mechanism to be rational \emph{a priori} for the subject to implement, it must be that $\expec[r|c(S)] - \expec[r|c(P)] > \expec[\sum \pi]$ where $\pi$ is either the result of a Nash equilibrium or a dominant strategy (i.e. we set all elements of $\hat{s}$ jointly to maximize $\sum \pi$, even if this does not a equilibrium for the experts).

Note that a multiplicative transformation of the rewards preserves the incentives. We denote the multiplicative constant that scales the payments by $\alpha$.

\begin{mech}[Cheap and Efficient Direct Mechanism]
Set

\[
    \pi_i = 
\begin{cases}
    \alpha (r - \expec[\hat{r}_{-i}] ),& \text{if } \hat{c}_{-i} \neq c\\
    0,              & \text{otherwise}
\end{cases}
\]

The rescaling parameter $\alpha>0$ is chosen ex ante based on $P$ such that: $ \expec[\sum \rho_i] < \expec[r|c(s,P)] - \expec[r|c(P)] $. This can be achieved by setting it such that

 $\alpha >   \frac{\expec[r|c(s,P)] - \expec[r|c(P)] )}{\sum \expec[\pi_i|P] }  $. 

\end{mech}


%\NDP{Initiall I tried instead of just a multiplier $< 1$, having a gneeral function $g$ with $g(0) = 0$, and $g$ is monotonically increasing in $p_i$. But this doesnt work if you lower the negatives more than the positive for example you fuck up the payments. Do we prove the scaling has to be a multiplicative, an aditive breaks it (if positive cnat help with budget and if negative can cause it to be irational for experts to enter if expected value of expert is bellow, while non linear transformation instead of linear multipler doesnt preserve the expectations and tus can also break the incentives of the experts to be truthful)}

\begin{lem}
	The rescaling of the mechanism preserves the incentives of experts.
\end{lem}

\begin{proof}
	As they are set \emph{a priori} based on expectations only, $\alpha$ is invariant to any reports the experts make. Since the transformation is a positive rescaling, whichever report maximizes payoffs remains unchanged. 
\end{proof}


\begin{lem}
	Entering the mechanism is positive expectation for the subject.
\end{lem}

\begin{proof}
  By construction $\alpha$ is chosen so that $\expec[\sum \rho_i] < \expec[r|c(s,P)] - \expec[r|c(P)]$
\end{proof}


\begin{lem}
	Entering the mechanism is positive expectation for the experts in the revelation BNE.
\end{lem}

\begin{proof}
In a case where all other signals are being reported truthfully, since a truthful signal cannot lower the expected reward of the optimal chosen action and the transformation of the payoff is linear, and the expert always has the option of reporting their true signal, the expected return in the revealing BNE of entering is weakly positive.
\end{proof}


\begin{thm}
	The scaled efficient mechanism is individually rational in the truthful equilibrium for all agents, experts and subject.
\end{thm}

\begin{proof}
Immediate from the two previous lemmas, since the subject and experts are all the agents involved.
\end{proof}

One natural concern is that there are potentially other equilibria beyond the full revelation equilibrium in these mechanisms. This is particularly clear in the case when there is complementarity between signals: if the other expert's reports are not truthful, it is not in general optimal to be truthful.


\subsection{Dominant Mechanisms}

\begin{defn}[Dominant Strategy Truthfulness]
	A Mechanism and prior distribution are \emph{Dominant Strategy Truthful} for an expert if reporting their true signal maximizes their expected payoff for any set of reports by the other agents. 
\end{defn}

The incentive compatibility in the VCG-style Mechanism is only a Bayes Nash Equilibrium, and not a dominant strategy. For example, if another expert does not report their signal truthfully, an expert might maximize the reward by making a countervailing report that is not truthful, to cancel out the other untruthful expert. 


%start using subject without introducing it,  
%why are we doing this? motivate
% % make sure you get 
% \begin{eg}[mechanism is not dominant-strategy incentive compatible]
% 	Consider a setting with a reward maximizing subject with probability 1, and two a priori equally informed experts, and two possible actions ${A,B}$. Consider the situation where expost the two experts know with certainty that the expected rewards are $0,0.9$ and one of them reports $1,0$. A truthful report would lead to choosing action $A$ (the average of the two reports) with rewards of $1$ while a report of $0,2$ would cause the max to selec action $B$ and obtain a reward of $2$.
% \end{eg}

\subsection{A sufficient condition for dominant truthfulness of an expert in efficient mechanisms}

In general the efficient\footnote{Mechanisms that are not efficient are trivial to make weakly dominant strategy truthful, for example by disregarding reports and always picking an arbitrary action.} mechanism is not dominant strategy incentive compatible, since, for example, an expert agent who inverts their reports would make the other experts also misreport to try to compensate if possible, as seen in the example above.

Consider a expert's \emph{unilateral value}, the expected value of selecting the optimal action conditional only on their signal, which we denote by  $\expec[ r| c_{i}]$. A \emph{unilaterally sufficient expert} is one where $\expec[r|c_{i}] \geq \expec[r|c_{s_i \cup s_{-i}}] \forall s_{-i} \forall s_{i}$, that is, the expert's signal pins down a choice of action that obtains expected optimal rewards irrespective of any other possible signal received by the other experts.



\begin{lem}
	In the presence of a unilaterally sufficient expert our VCG-style Mechanism and its scalings pay no other experts.
\end{lem}

\begin{proof}
    The other reports never change the chosen action, thus always receive payoff of 0 in the payment rule.
\end{proof}


\begin{lem}
	A unilaterally sufficient expert has truthfulness as a dominant strategy in a VCG-style mechanism.
\end{lem}

\begin{proof}
    By the definition of efficient the mechanism maximizes the reward given the reports; by the definition of sufficiency the expert's report being truthful is all that is required for this.
\end{proof}

% \begin{lem}[necesary]
% 	A expert must be unilateraly sufficient if an efficent mechanism is dominant straegy for them.
% \end{lem}
% %THIS IS WRONG. not the right condition, the report with just you might be lower than with the others, but that doent mean you have a better coice than truth telling, it might all be the same, so it is only strict dominat that this is necesary for.
% \NDP{We should be able to find the necesary condition from the above.}
% \begin{proof}
%     By contradiction. Assume the expert is not unilateraly sufficient, then by its definition of unilaterally sufficient there is a $s_{-i}$ such that  $\expec[r|c_{i}] < \expec[r|c_{s_i \cup s_{-i}}]$  for some pair of ther other expert signals $s_{-i}$ and the signal of the expert $i$, $s_{i}$. 
% \end{proof}
% \begin{thm}
% 	A unilaterally sufficient expert is necesary and sufficient for a mechanism 
% \end{thm}

% \begin{proof}
%     Inmidiate from previous two lemmas
% \end{proof}
% a unilaterllay sufficient expert is necesary nto just sufficient.

% allways takers and defiers, 


\section{A Bidding Mechanism}

In many practical applications of interest, direct signal mechanisms might be impractical. It might be that the signals can't be practically reported: for example, because while the expert knows something when they see it, they do not have a vocabulary to unambiguously express it. It can also be because the mechanism may not have access to the prior  probability distribution and thus the signals can't be unambiguously aggregated. 
If we replace the reports in the direct mechanism by bids, and we allow the winner of the auction to pick the action (after observing the losing bids), we obtain a mechanism that doesn't make any strong assumptions beyond that the agents understand the mechanism and are profit driven.



\begin{mech}[Bidding Mechanism]

Each agent observes their signal and report a bid $b_i$.
The agent with the highest bid in the auction, the \emph{owner} of the choice, observes the full set of bids and then chooses an action $c$; the subject then selects the action $a$ and the reward $r$ is received. 

Denote by $o_{i}$ a indicator variable encoding with a value of $1$ if the agent $i$ was  \emph{owner} of the choice, and let $b_{\hat{2}}$ denote the value of the second highest  bid. If both agents' bids are equal, select the owner between them uniformly at random.

\[
    \pi_i =  
\begin{cases}
        r - b_{\hat{2}} ,& \text{if } o_{i} = 1 \\
		0,              & \text{otherwise}
\end{cases}
\]
\end{mech}


This mechanism has several problems, for example, a natural stylized setting is:


\begin{eg}[Two Experts and Actions with IID Signals]\label{eg:two-iid-signals}
	Let there be two experts. Two actions ${\text{treatment},\text{control}}$, each of which has rewards drawn independently from a corresponding Bernoulli distribution with Jeffreys prior. Each expert's signal consists of one draw from each of the two distributions.
\end{eg}

A BNE exists where each agent bids the posterior expected value of the arm with the highest reward conditional on having won the bidding.
Given being the owner of the choice and observing the bids of the other agent, it is possible to deduce 
The winner, after observing the bid of the other agent, can deduce if the other agent observed 0, 1, or 2 positive draws. For the 0 and 2 positive draws, the agent's optimal choice and the efficient choice are both selected by selecting the arm the agent had a positive draw from (if both or neither, then either arm is equal to the efficient choice). 
However, in the situation where both agents observe exactly one positive draw, the efficient outcome in the bidding mechanism is selected less than in the efficient direct mechanism.


For some information structures the bidding mechanism still aggregates information efficiently, for example:

\begin{defn}[Full set of specialist experts]\label{defn:specialists}
	If each expert knows the expected outcome conditional on one action and knows they don't know what happens under other actions, and there is at least one expert who is informed about each action.
\end{defn}

Note that this situation fails to satisfy the unilaterally sufficient expert requirement. The bidding mechanism is able to meaningfully aggregate information in at least some information structures; note no single expert knows the optimal action.

% Further, by the revelation priciple we can create a direct mechanism that generates this outcome, and for this class of information structures is efficient (through clearly it will not be efficient for other information sturcutres, for example the one in the fully complemetary information example)


%\section{Summary}



\section{Bid and Signals Without Priors in the Mechanism}

We now combine the bid based and direct mechanisms to reduce the requirement on the common prior, and in particular that the mechanism has access to it. 
While formally to analyze the BNE we still require the experts to have access to the prior, the mechanism can aggregate even in the absence of this to the degree that the signals be still informative to the expert who is the highest bidder.
Note that the incentives are also well aligned, in the sense that is precisely the expert for whom the mechanism makes the highest payments. 

Even in the absence of common priors, it may still be possible for experts to convey to each other through their signals (even if it is not possible for the mechanism to evaluate the value of such signals) and there are sufficient degrees of freedom in the scaled mechanism to add a simple modification that accounts for this.
One possible change is to add to all payments a further share of the reward of the mechanism while displaying their reported signals to the winner of the auction before they select their action. That is, we replace the 0 payments to agents that do not make a report that alters the chosen action with a share of the gains of the mechanism.

Denote by $b_i$ the bid part of agent $i$'s report, and by $\hat{s_i}$ the signal part of their report, by $b_{\hat{1}}$ the highest bid and by $b_{\hat{2}}$ the second highest bid. If multiple bids are tied for highest, we randomize which one is treated as the highest and which one is considered the second highest.

\begin{mech}
The mechanism receives bids and signal reports from all experts, reveals the signal reports and bids to the winner of a second price auction for a share of the reward and allows them to select a chosen action; this chosen action $c$ is announced to the subject, who picks an actual action $a$ after which the reward $r$ is revealed and payments made according to:

\[
    \pi_i = 
\begin{cases}
    \alpha (r - b_{\hat{2}} ) ,& \text{if } b_i = b_{\hat{1}}\\
    \beta r,              & \text{otherwise}
\end{cases}
\]

\end{mech}

As before $\alpha$ and $\beta$ are set ex ante so as to limit expected payments to be lower than the efficiency gain from the mechanism. This can be achieved by setting them such that $(\alpha + \beta)N < 1$.
Thus, an expert's optimal strategy is to bid the expected value of the reward conditional on their signal and on having the highest bid.

This mechanism does have the same problem as the sharing mechanism in that useless experts' entry is costly to the mechanism or to other experts.
Since we are attempting to avoid the use of a prior by the mechanism, and we are in the one shot setting, there is in general (for arbitrary information structures) no generic way to estimate if a given signal is worthless, even when it is pivotal, since it involves estimating the reward of the action not taken \cite{della2012crowd,waggoner2014output, witkowski2014robust}.



While this mechanism is somewhat convoluted and practically implausible for open marketplaces, due to the payment of useless experts, it is useful conceptually in understanding the more practical mechanism for the sequential case in the next chapter.



% \section{conclusion}

% We presented the first incentive compatible efficient decison market (the VCG style mechanism).
% \NDP{TODO}



