%!TEX root = main.tex
% optimal decision elicitiation algorithm

Consider a setting with multiple experts providing advice to a subject, who wishes to incentivize them to inform them of which of a set of available actions maximize the reward.
One natural way to attempt to do is by applying the machinery of prediction markets based on sequentially shared proper scoring rules, and only settlign the markets where actions are taken. Doing this in an incentive compatible manner for the experts is however incompatible with maintaining the subjects freedom to select the action that appears optimal ex-post (\cite{othman2010decision,  chen2014eliciting}, that is using the max decision rule. 
The core of the problem with using the machinery of prediction markets in the decision setting is that at the point where the mechanism has correct belief over the optimal action but not others, a expert  can profit by changing expected rewards to make optimal action appear worse than an action for which the expected reward can be corrected.


The guiding design criterion in this work is to restrict as little as possible the decision that the subject must take (maximizing their freedom) while still providing good incentives to the experts. No previous mechanisms in the literature can truthfully aggregate arbitrary signals over many experts in BNE. 
We first focus on a direct efficient mechanism in the style of VCG mechanism. Experts directly report their signals to the mechanism, which then uses them to compute the optimal action given the prior to output to the subject. This requires  the experts and the mechanism having access to a common bayesian prior, over the joint probabilities of the rewards, true signals, the output action and the response of the subject to a given output of the mechanism. There is a BNE that aggregates all information over $N$ experts, unlike the case in the previous mechanisms in the literature.
We then analyze a simple bid based variation of the mechansim, and provide a sufficient conditions on the signal structures where information can be fully aggregated; we further show that these conditions are sufficient to make truthfulness dominant incentive compatible.  


\section{Model}

We consider a single subject with access to $K$ possible choices, and access to a set of $N$ experts, each of whom have access to some signal $s_i$ which are potentially informative about $\expec[r|a,c,S]$, where use $S$ to denote the vector containing all experts signals.  $P$ denotes the apriori joint probability distribution over $(r,a,c,S) $ which is common knowledge. 

Thus given a mechanism $M$, and denoting unobservable characteristics (the latent state) as $u$


%\begin{figure*}[t]
%	\centering	
%	\include{ICEBDAG}
%	\caption{Bandit with Compliance Awareness DAG}
%\end{figure*}


To map to the mechanism design literature the $P$ would be over states of the world in $\Omega$ and each state of the world consists of a agent type (complier probability and action outcome and the value a utility functin placed on it, which equates to rewards in our notation) and the signals of each expert in that state of the world.

A direct mechanism anounces a payment rule $p_i(\hat{s}, c,a,r)$, with $p_i$ being the payment to expert $i$, with $\hat{s}$ being the reported signals, $\hat{c}$ being the reward maximizing choice given the reported signals, and by $c^{*}$ the reward maximizing choice given the true signals.
Experts receives their signals $s_i$, makes a reports $\hat{s}_i$ to the mechanism, which then outputs a chosen action $c$.
The subject observes the action chosen by the mechanism $c$, and takes a (potentially different) action $a$. A reward $r$ is observed, and the mechanism makes the corresponding payments.

An experts $i$ report is truthful when $\hat{s}_i=s_i$. A mechanism is incentive compatible when truthful reports maximize the payment experts receive and this holds for all experts. This can be in dominant strategies or in a bayesian nash equilibrium.  We seek efficient mechanisms, that is $c^{*} = \hat{c}$ for all posible signals.

\section{Simple Mechanisms and Fundamental Limits}

Consider the following adaptation of the classic complemetary knowledge example from the full supervised setting, which originates in \cite{geanakoplos1982we}, to the bandit setting:

\begin{eg}[complementary experts]\label{eg:comp-ex}
	Let there be two experts, two actions ${\text{treatment},\text{control}}$ and four equal probability states of the world, ${A,B,C,D}$, with payoffs to the actions correspondingly as ${(0,1),(0,-1),(-1,0),(1,0)}$. Let one expert oberve that they are in either ${A,B}$ or ${C,D}$ and the other ${B,C}$ or ${A,D}$. A uniform random strategy achieves an expected value of 0. An optimal strategy with access to a single expert (either one) achieves a value of 0. Using the signals of both we can achieve reward 1. Thus the VCG payments are $1$ to each, and the mechanism improves the subjects welfare by $1$ while making $2$ in payments. 
\end{eg}

In the example, by construction, it is common knowledge that each player’s expectation of the value of the reward conditional on either action is zero, even though it is also common knowledge that the realized value of the reward conditional on either action is not zero, and that the traders’ pooled information would be sufficient to determine the optimal arm. Thus, even if the traders repeatedly and truthfully announce their posteriors, as in \cite{geanakoplos1982we}, they will never learn the true optimal arm. 
Thus, there is a fundamental limit to the information that can be aggregated by market like mechanisms that rely on prices for information transmition (indirect mechanisms) relative to what could be known if the signals themselves where aggregated. 

%At a fundamental level, if the price space is smaller than the intrinsic dimensionality 
%\NDP{this cant be totaly right, one could do some Z curve type encoding of any finite signals space into the price line, but this feels very artificial, and cerainly would open horible things in a price line with arbitrage, but it seems counter some more evidence monotonically raises probability requirement}

%While some, such as \cite{} argue that the above situation is artificial, \cite{ostrovsky2012information}
% DEFINITION 2: Security X is non-separable under partition structure Π if there exist distribution P on the underlying state space Ω and value v ∈ R such that:
% (i) P(ω) is positive on at least one state ω in which X(ω) ̸= v; (ii) For every player i and every state ω with P(ω) > 0,
% 􏰕
% P(ω′)X(ω′)
% EP X|Πi(ω) ≡ 􏰕 P(ω′) =v􏰷
% 􏰥 􏰦 ω′∈Πi(ω)
% ω′ ∈Πi (ω)
% ￼Otherwise, security X is separable.
\subsection{A Simple Direct Reward Sharing Mechanism}


Let us first consider a very basic direct mechanism, which will help us understand the model and the limitations that subjects freedom imposes. 

Perhaps the simplest class of mechanisms is based around the idea of sharing the rewards from the taken action with the experts. For the simple expert case this is mentioned by \cite{othman2010decision}, but the idea also extends to the multiple experts case with common priors. 

A simple mechanism that is strictly (if the signal is informative) incentive compatible (in equilibrium) for an expert to reveal their signal when subjects are utility maximizers is to give all experts a share of the reward. Equivalently (in expectation) run a lottery after the reports are submitted that assigns a share of the reward to the expert that wins. 

In this case the payment rule is invariant to the reports, and defined as $\pi_i  = (\alpha / N ) r $ with $\alpha < 1$. Note that we are not defining the payment rule to be conditional on the subjects actual action in any way. % In particular, it might naively seem appropiate to only give the share when the chosen action is the actual action carried out. 

We say a expert is useless if knowing their signal would not change the chosen action for any possible set of other agents signals (including the empty set, i.e. the prior).

This mechanism is problematic in a pair of related ways: it pays out even when experts signals are useless.
A corrolary of this is that the entry of useless experts reduces the payment received by valuable ones or the budget needed by the mechanism.



\subsection{Scoring Rule and Void Decision Market Mechanisms}

A somewhat more complicated mechanism is to attempt to use the machine of sequential proper scoring rule based market makers to predict the rewards contigent on choosing each possible action. The market for the chosen action can then be settled in the standard manner, and the other markets voided. 
We term these Scoring-rule and Void Decision Market Mechanisms (SVDM). The basic idea is to use a sequentially shared proper socring rule to run a prediction market for the value of the reward conditional each possible action, and to void the markets for the non-chosen actions.  

%TODO
%\begin{eg}[With a utitlity maximizing subject an expert can benefit from exaggerating the success probability of a suboptimal action]
	from \cite{othman2010decision}
%\end{eg}


THEOREM 1. There does not exist any strictly proper scoring rule/deterministic decision rule pair.

More generally, an immediate corollary to a theorem X of \cite{chen2014eliciting} states that Randomized decision rules with full support are necesary for incentive compatible SVDM mechanisms.
Note that this implies all the problems of the max decision rule apply for example to a Thompson style randomized decision rule, since they can still be manipulated not to have full support over the action by a sufficiently bad report.

If a subject is free to either maximize their expected utility at decision time (and lacks a credible commitment device beforehand, or wishes to mantain its freedom) then a SRDM is not Incentive Compatible for them. Further, the cost of making the probabilities of dominated actions small is to make the payments contigent on when they are taking place conmesurably large.

Beyond the reduction in freedom fromthe pre-commitment to randomiation with full support, it also rules out \emph{efficiency}, since by definition if actions known to be dominated are played with positive probability, the mechanism is not efficient in it's allocation of the choice of action. 

A further limitation of such methods is inherited from the prediction markets and more generally from posterior anoucement games analized in \cite{ostrovsky2012information}: fully complemetary signals between two experts are not aggregated. 

\section{A Direct Mechanism for Efficient Optimal Choice Elicitation}

We now consider a VCG style mechanism for the optimal decision elicitation problem. The sense in which it is VCG is that it is efficient (always chooses the action whose choice maximizes rewards, note this can be different form the actual action which if carried out with perfect compliance would do so) and we compensate subjects for the extenrality their signal imposes; since truthful reports cannot by definitiion lower the expected value of the optimal action relative to having chosen the action without using the extra signal, these are strictly positive when all reports are truthful. 

Our use of received payoff instead of expected payoff avoids the use of counterfactual that use the signal reported by the agent itself, which enables the mechanisms to be turthful in equilibrium.
% This seems problematic. For example, if noncompliance leads to lower reward (which is presumably to be expected if experts know more than subject) then experts' payouts is reduced due to a subject's capriciousness.
%This is especially problematic if payouts are negative due to subject's noncompliance.
%\NDP{I initially tried setting to void market if action nto followed, but this creates perverse incentives, where the subject might not follow the advice and receive a lower payoff to avoid payment. While your statements abotu the experts are true they (A) the prior taking into account noncompliance makes these expectations workable, you take into account the fact that some advice might not be followed with higher probability. (B) the \emph{no defiers} (terrible name, sinc eit is even stronger than that, uniform noncompliance might be a better term), is a sufficient condition to rule this out.}

All agents know a common prior that gives a proper prior probability distribution of rewards over all posible signals, chosen actions and actual actions.

\begin{mech}\label{mech:vcg-style}[Efficient VCG-style Mechanism]


%$\hat{S}_{-i} = \bigcup \hat{s}_j  \forall j \neq i \in N $ then the expected reward given the others reports is:

For each expert $i$, compute the optimal action to choose without using that experts report (i.e. marginalizing over the prior on signal $i$ signal), denote this action $\hat{c}_{-i}$ and it's expected reward: $E[\hat{r}_{-i}] = E[ r| \hat{c}_{-i}, \hat{S}_{-i}] $


The payment rule is announced as follows:

\[
    \pi_i = 
\begin{cases}
    r - E[\hat{r}_{-i}] ,& \text{if } \hat{c}_{-i} \neq c\\
    0,              & \text{otherwise}
\end{cases}
\]

%

Each expert reports their signal, the mechanism calculates the action that maximizes the reward $c$, and chooses it. After observing the actual action taken $a$ and its reward $r$, the corresponding payments are made, this concludes the mechansim.

\end{mech}


Conditional on the action taken the payments do not depend on the reported signal of agent $i$. That is $i$ only affects their received payments with their report via the choice of action. 
Note, if you take out the if and reward players no matter what, all you do is increase the variance but dont change the expectation, since if the action is unchanged and under the assumption the prior is correct, it's expected reward must be zero as $E[\hat{r}_{-i}] = E[r|P,c]$. The  mechanism and its properties still hold under risk neutral expert,  this is because the expected reward when using all signals and when using only the other agents signals has to be the smae if the same action is being taken. 


\begin{lem}\label{lem:affect}
	The only way an expert's report affects their payments is via the chosen action.
\end{lem}

\begin{proof}
There are two terms in the expression for the payment rule $\pi_i$: the received reward $r$ and expected reward $E[\hat{r}_{-i}]$ given the counterfactual that expert $i$ is ignored. 
The first term is the reward received after executing the chosen action, and therefore clearly only depends on the chosen action. 
The second term is explicitly constructed so as not to use the report by expert $i$. 
\end{proof}


%TODO: be more precise about what we mean by same signal
\begin{lem}[redundant experts]
	When two or more experts report the same signal, they all get payoff zero. 
\end{lem}

\begin{proof}
	Given the other experts reports, it is not possible for the same signal
\end{proof}

\begin{lem}
	Useless experts cannot profit from participation
\end{lem}

\begin{proof}
This is inmidiate from how the payment rule and useless experts are defined, since by definiion there is no information that can be reported to raise $r$ and that is all that can lead to higher rewards.
\end{proof}

%TODO pin down useless more formally still

\subsection{Incentive Compatible and Efficient}

\begin{thm}[Bayes-Nash Incentive Compatibility]
	A Bayes Nash Equilibrium exists where all experts truthfully report their signals.
\end{thm}

There is an equilibrium where all experts maximize their payment by maximizing the probability that the action with the highest reward is taken; if all other reports are truthful, and under a no-defiers assumption, then this is optimized by being truthful.

\begin{proof}
For a given expert $i$, let all other experts truthfully report their signals. By Lemma~\ref{lem:affect}, the only effect an expert has on their payment is via their effect on the chosen action $c$. Given all other experts are truthful, it follows by the definition of Mechanism~\ref{mech:vcg-style} that if expert $i$ is also truthful then the mechanism will select the $c$ that maximizes the expected $r$, thus maximizing the expert $i$'s reward. Truthfulness is therefore a Bayesian Nash equilibrium.
\end{proof}

\section{Scaling Payments and Rational Entry}


The mechanism is however potentially negative expetation if subjects are to compensate the experts via the mechansim.  That is the payments can be more than the improvement in the reward the mechanism creates. For example in Example~\ref{eg:comp-ex} the payments are double the payments. In these situations it is not rational for the subject to enter the mechanism.


As presented the VCG style direct mechanism can have higher payments than the benefits it provides in terms of higher rewards (if there are states of the world with sufficiently high reward differentials and a sufficiently large number of experts with complementary signals). Hence, the subject might be better off not participating \emph{a priori}. Here we introduce a variation on the mechanism that re-scales payments using the prior so a subject \emph{a priori} wishes to participate in the mechanism. The mechanism takes advantage of two observations. Firstly, one can set $\alpha$ prior to receiving signals from experts based on the prior. Secondly, by Lemma~\ref{lem:affect} experts do not care about the chosen action beyond how it affects their payments. 

The second observation does not hold in standard VCG mechanisms: if they cared about the action then you need to compensate them exactly for their externality. While this doesn't make an explicit appearance in the proof it is the reason why we can scale the payments to alter the budget in a way that VCG mechanisms cannot: a change in the allocation that leaves payments unchanged alters the utility of agents in the VCG setting but not here, so the payments in the VCG setting have to move to counter-balance this precisely, limiting the freedom with which we can choose them.

\NDP{Explain relation to the  Clarke pivot rule. With the Clarke pivot rule, the total amount paid by the player is: (social welfare of others if i were absent) - (social welfare of others when i is present).
This is exactly the externality of player  i}

In the model we have presented a expert pays no cost when aquiring their signals, and so in the single agent case the payment made by the subject for signals can in principle be arbitrarily close to zero while still incentivising truthful reports (for example the share of the reward mechanisms achieves this). We now study when payments rules can be scaled to create ex-ante in expectation arbitrarily small expected payments to the experts. As usual, we assume risk neutral experts. 



Let $E[r|c(s)]$ denote the expected reward obtained from choosing the optimal action using all signals if they where reported truthfully, and $E[r|c(P)] $ the expected reward from picking the action using only the prior and no signals. Thus $E[r|c(S)] - E[r|c(P)] $ is the expected surplus from using the information in the truthful equilibrium of the mechanism relative to using only the priors. For an efficient mechanism to be rational \emph{a priori} for the subject to implement, it must be that $E[r|c(S)] - E[r|c(P)] > E[\sum \pi]$ where $\pi$ is either the result of a Nash equilibrium or a dominant strategy (i.e. we set all elements of $\hat{s}$ jointly to maximize $\sum \pi$, even if this does not a equilirium for the experts).

Note that a constant afine transformation of the rewards preserves the incentives. Denote by $\alpha$ that scales the payment.

\begin{mech}[Cheap and Efficient Mechanism]
Set
\[
  \rho_i  := \alpha \pi_i
\]
The rescaling parameter $\alpha>0$ is chosen \emph{a priori} based on $P$ such that: $ E[\sum \rho_i] < E[r|c(s,P)] - E[r|c(P)] $. This can be achieved by setting an alpha such that

 $\alpha >   \frac{E[r|c(s,P)] - E[r|c(P)] )}{\sum E[\pi_i|P] }  $. 

\end{mech}


%\NDP{Initiall I tried instead of just a multiplier $< 1$, having a gneeral function $g$ with $g(0) = 0$, and $g$ is monotonically increasing in $p_i$. But this doesnt work if you lower the negatives more than the positive for example you fuck up the payments. Do we prove the scaling has to be a multiplicative, an aditive breaks it (if positive cnat help with budget and if negative can cause it to be irational for experts to enter if expected value of expert is bellow, while non linear transformation instead of linear multipler doesnt preserve the expectations and tus can also break the incentives of the experts to be truthful)}

\begin{lem}
	The rescaling of the mechanism preserves the incentives of experts
\end{lem}

\begin{proof}
	As they are set \emph{a priori} based on expectations only, $\alpha$ is invariant to any reports the experts make. Since the transformation is a positive rescaling, whichever report maximizes payoffs remains unchanged. 
\end{proof}


\begin{lem}
	Entering the mechanism is positive expectation for the subject.
\end{lem}

\begin{proof}
  By construction $\alpha$ is chosen so that $E[\sum \rho_i] < E[r|c(s,P)] - E[r|c(P)]$
\end{proof}


\begin{lem}
	Entering the mechanism is (weakly) positive expectation for the experts in the revelation BNE.
\end{lem}

\begin{proof}
Since a truthful signal cannot lower (if all other signals are being reported truthfully) the expected reward of the optimal chosen action and the transformation of the payoff is linear, and the expert always has the option of reporting their true signal, the expected return in the revealing BNE of entering is weakly positive.
\NDP{Do it in algebra?}
\end{proof}


\begin{thm}
	the scaled efficient mechanism is individualy rational for all agents, experts and subject.
\end{thm}

\begin{proof}
inmidiate from the two previous lemmas, since the subject and experts are all the agents involved.
\end{proof}




\section{Dominant Mechanisms}

\begin{defn}[Dominant Strategy Truthfulness]
	A Mechanism and Prior Signal Distribution are \emph{Dominant Strategy Truthfull} for an expert if reporting their true signal maximizes their expected payoff for any set of reports by the other agents. 
\end{defn}

The incentive compatibility in the previous section is only a bayes nash equilibrium, and not a dominant strategies. In particular, if another expert does not report their signal truthfully, an expert might maximize the reward by making a countervailing report that is not truthful, to cancel out the other untruthful expert. 

\begin{eg}[mechanism is not dominant-strategy incentive compatible]
	Consider a setting with a reward maximizing subject with probability 1, two possible actions, where two experts know with certainty that the rewards are $1,2$ and one of them reports $1,0$. A truthful report would lead to choosing the first action (the average of the two reports) with rewards of $1$ while a report of $0,2$ would cause the max to select the seccond action and obtain a reward of $2$.
\end{eg}


\subsection{A sufficient condition for dominat truthfulness of an expert in efficient mechanisms}

In general the efficient\footnote{Mechanisms that are not efficient are trivial to make weakly dominant strategy truthful. For example disrewarding reports always picking an arbitrary action} mechanism is not dominant strategy incentive compatible, since (for example) a expert agent who inverts their reporrts would make the other experts also misreport try to compensate if possible, as seen in the example above.

Consider a experts \emph{unilateral value}, the expected value of pickign the optimal action conditional only on their signal, which we denote by  $E[ r| c_{i}]$. A \emph{unilaterally sufficient expert} is one where $E[r|c_{i}] \geq E[r|c_{s_i \cup s_{-i}}] \forall s_{-i}$, that is the experts signal pins down a choice of action that obtains expected optimal rewards irrespective of any other possible signal received by the other experts.

\begin{lem}
	A unilaterally sufficient expert has truthfulness as a dominant strategy in an efficient mechanism with shared rewards.
\end{lem}

\begin{proof}
    by definition it maximizes the reward irrespective of other reports.
\end{proof}

\begin{lem}
	In the presense of a unilaterally sufficient expert our vcg-style mechanism and its scalings at most pays the sufficient expert.
\end{lem}

\begin{proof}
    the other reports never change 
\end{proof}


\begin{lem}
	In the presense of at least two unilaterally sufficient experts our vcg-style mechanism makes payments 0 in expectation in the full revelation BNE. 
\end{lem}

\begin{proof}
    Since one expert is sufficient, the other experts (sufficient or not) reports makes no change in the chosen action expected reward, and so the expected payoff is 0. This holds for each of the sufficient experts.
\end{proof}






\subsection{Noncompliance and Incentive Compatibility}

A natural question that arrises is how to handle the case where the action that is optimal given the reports (the chosen action under perfect compliance) is not the actual action taken by the subject. The three natural strategies from bandits with compliance awareness have their counterparts. Three natural strategies are:

\begin{itemize}
\item make payments irrespective. 
\item make the payment for the $\alpha r_a$ but do not require the payment of $b_{i-1}$.
\item make no payment, and require no payment.
\end{itemize}

Only the first is incentive compatible. TODO: formalize. Sketch: a crucial property is that w separate bids and reports, this lets the reports be truthful while the bids are shaded (as is standard in common value seccond price auction). Further, it means that noncompliance (given the no defiers assumption) 
\DBA{maybe I'm missing something. But if the subject has a strong tendency to pick low-reward actions, then the experts are disincentivized from providing any advice at all, since they will likely receive negative payouts}
\NDP{The prior is over the noncompliance (what you are terming it the tendency to pick low actions here) }


If we do not require the payment, it can incentivize experts to report in such a way as to encourage non-compliance, since this would increase their payout. \DBA{example}


If we void the payment completely this can have the oposite effect, biasing experts away from reporting the \DBA{Is this paragraph dependent on agent's having a model of the subject's noncompliance? E.g. If subject's noncompliance is random (ignore advice with probability $p$ and then pick action uniformly), are the second and third options incentive compatible?}


for a cancer example; the chemiotherapy specialist might explain the likely side effects conditional on their knowledge of the specifics of the patient (the rapidly dropping cost of sequencing a genome means this) without needing to understand the relative value the patient places on discomfort relative to life lengthening, while the surgeon might explain the (again subject tot he specific characteristics of the subject) risks he foresees in the surgury (in contrast to the baseline risks of the populatin that gets the procude which is what cna be observed, a reasoable prior) for that patient, without needing to udnerstand the risk aversion of the patient which would be necesary for calculating their utility.

the subject (oracle style) can then be queried for their chosen action and expected utility for different subsets of the signals (for every expert we need to query what the action (and the expected payoff) would be without that experts signal having been reported)

contrast the information structure in the cancer example and its non separability 


\section{A bidding mechanism }

In many practical applications of interest, direct signal mechanisms might be impractical. It might be that the signals can't be practically reported: for example, because while the expert knows something when they see it, they do not have a vocabulary to unambigously express it. The experts may disagree about the prior probabilities and thus the signals can't be unambigously aggregated, or the mechanism doesn't have access to the prior.


If we replace the reports in the direct mechnaism by bids, and we allow the winner of the auction to pick the action, we have a mechanism that doesnt make any strong assumptions beyond that the agents understand the rules of the game.

For some information structures this still aggregates information well, for example:

\begin{lem}[specialist experts]
	if each expert knows the exact outcome conditonal on one action and knows he doesnt know what happens under other actions, and there is at least one expert that is informaed about each action.
\end{lem}

Note that this fails to satisfy the unilateraly sufficient expert requirement. Further, by the revelation priciple we cna create a direct mechanism that generates this outcome, and for this class of information structures is efficient (through clearly it will not be efficient for other information sturcutres, for example the one in the fully complemetary info example)

For other information structures it does not work, for exmaple 
\begin{eg}
	the classic example without separability that fails in the bayesian games so broadly (TODO Add cite) also fails here. 
\end{eg}

%\section{Summary}




\section{Freedom and Limits to Defiance}

If we consider subjects with potentially unrestricted freedom, i.e. subjects are not necesarily expected reward maximizers nor alway-takers, then the mechanism is not necesarily truthful, even for a single expert. 

\begin{eg}[total freedom yields bad incentives for a single expert]
	For example, consider a subject that has a prejudice in favour of treatment A, and so will take it unless the expected reward of treatment B is more than 10 utils highers. Consider a expert with access to a signal wich is an unbiased estimate of the rewards over both actions, receives a signal  that B reward is higher by 9 utils. The expert is strictly better off reporting that his signal has B as more than 10 better.
\end{eg}

It is clear that such preference structures on the part of the subjects makes attaining both truthfulness and efficiency impossible. That is, in such situations misdirection is required to achieve efficiency. More pathological cases can lead to more severe problems:

\begin{eg}[subjects who defy experts yield perverse incentives]
	More generically we can consider of an agent who does the oposite of what maximizes reward (the min decision rule), this creates incentives for experts to flip the ordering that their signals imply. 
\end{eg}

Thus, it appears that providing unrestricted freedom in the broadest sense to subjects makes the setting hopeless. 

One restriction on subjects freedom that is sufficient to allow (in the single expert setting) dominant strategy truthful mehcanism is \emph{maximizers or allways takers}: assuming that all subjects are either utility maximizers (compliers under a efficient mechanism) or have some action they will take irrespective of the reports of the experts (always takers or never takers in the binary setting). Note for example that in the canonical two treatment setting this is equivalent to the usual no defiers assumption. 
This preserves substantial freedom, in that it is not required the subject known a priori that they will compliers, their realization of the always taker type could come after the mechanism has been run and before the action is taken. 

While this is a strong assumption to make, it is still substantially weaker than requiring subjects to follow ex-post dominated strategy with a given positive probability ( and since the payments are depedent on this probability this needs to be followed precisely), which is what is required in the MSR and void type mechanisms.

This condition can be somewhat relaxed,  since the needed property it implies is that the mechanism choosing an action with higher expected reward if actually carried out leads to the expected reward conditional on the chosen action to be higher. Formally a sufficient condition is:
%at the cost of a loss of interpretation of the prices in the bidding mechanism,

\[
E[ ^{*}|c_i]  \geq E[ r^{*}|c_j] \text{ if }E[ ^{*}|a_i]  \geq E[ r^{*}|a_j]  \forall j \neq i \in K
\]

%TODO
%There is some extra flexibility more than no defiers which we should use, for example differential compliance rates for different actions, the mechanisms selects the action that most raises the reward not the one who has the highest reward (for example an action that has the second highest reward but 1\% noncompliance might be chosen instead of one  that has 99\% noncompliance and the highest reward. No defiers buys us the extra part that chosen is the highest reward action, so makes life easier for the subject (if the noncompliance depended on the signals the expert receives a utility maximizing decision maker would have to consider other decision markets noncomplaince characteristics in the prior before deciding how to interpret the chosen action; this removes such ambiguities and doesn't seem to loose too much generality)




%\subsection{Interpreting bids}


% TODO:
% \begin{eg}[IID signals for experts]\label{eg:iid-ex}
% 	Let there be two experts, two actions ${\text{treatment},\text{control}}$ each which rewards with abernoulli draws with probabilities either $\alpha,1-\alpha$ or  $1-\alpha,\alpha$. Let the prior over $\alpha$ be a beta distribution
% \end{eg}

% %The bids reflect the expected value of the mechanism choosing a particular action, not of that action being taken. \DBA{I'm confused. In previous section, ``each expert knows the exact outcome conditonal on one action'', and now its conditional on action being chosen, not taken. These sentences sentences seem to be at odds.} Example: if half are allways takers, the bid effectively waters down the true effect by half.

% \DBA{So the bids made by experts depend on the expert's model of the subject's behavior?}
% \NDP{correct, is this clear now form the text?}
%further, due to the winners curse, it is the expected effect conditional on having won the auction. 
%\DBA{can you write down how expected conditional on having won is computed?}

%\DBA{At this point, the interpretation of the bid has been qualified twice, and I'm lost}

%\subsection{A sufficient separability condition for efficiency}

%if each expert knows the value of a action the MSR and Void mechanism in the style of Hanson fail to be myopically incentive compatible when agents always follow the action whose price is maximal in the market (\cite{othman2010decision})




\section{A Bid and Signal Report Mechanism without Common Priors}

We now combine the bid based and direct mechanisms to reduce the requirement on the common prior, and in particular that the mechanism have access to it. While formally to analize the BNE we still require the experts to have access to the prior, the mechanism can aggregate even in the absence of this to the degree that the signals still be informative accross experts. 

The idea is that evenin the abscense of common priors, it may still be possible for experts to convey to each otherthrough their signals (even if it is not possible for the mechanism to evaluate the value of such signals) and that there is sufficient degrees of freedom in the scaled mechanism to add a simple modification that accounts for this.

The key change is to add to all payments a further share of the reward of the mechanism while displaying their reported signals to the winner of the auction before they select their action. That is we replace the 0 payments to agents that do not make a report that alters the chosen action with a  share of the gains of the mechanism.

Denote by $b_i$ the bid part of agents $i$ report, and by $\hat{s_i}$ the signal part of their report, by $b_{\hat{1}}$ the highest bid and by $b_{\hat{2}}$ the seccond highest bid. If multiple bids are tied for highest, we  randomize which one is treated as the highest and which one is considered the seccond highest.

\begin{mech}
The mechanism receives bids and signal reports from all experts, reveals the signal reports and bids to the winner of a seccond price auction for a share of the reward and allows them to select a chosen action, this chosen action $c$ is announced to the subject, who picks and actual action $a$ after which the reward $r$ is revealed and payments made according to:


\[
    \pi_i = 
\begin{cases}
    \zeta (r - b_{\hat{2}} ) ,& \text{if } b_i = b_{\hat{1}}\\
    \eta r,              & \text{otherwise}
\end{cases}
\]

\end{mech}

Thus a experts optimal strategy is to bid the expected value of the reward conditional on their signal and the posterior over the other agents signals conditional on having the highest bid. If the expert wins their signal report becomes irrelavant, as they already know their true signal.

This mechanism does have the same problem as the sharing mechanism in that useless experts entry is costly to the mechanism or to other experts. Note since we are attempting to avoid the use of a prior by the mechanismand we are in the one shot setting there is no way to estimate if a given signal is worthless. This will be however mostly avoidable in the repeated setting.  

Note that this analysis is strongly depedent on notions of equilibrium. For the same reason that experts do not have dominat strategies in the direct mechansim with their signal reports, they also do not have them here (instead of offsetting a non-truthful report with another non-truthful report in the mechanism the problem isnot this offsetting situation can happen )

%TODO hint at the value in the repeated setting of dropout type tricks to try to limit conspiracies.

Where as before $\alpha$ and $\beta$ are set so as to limit expected payments to be lower than the expected gain form the mechanism. 

%While this mechanism is somewhat convoluted and implausible in the one shot setting, it is useful conceptually in building up a practical mechanism for the sequential case in the next chapter. 
To the best of our knowledge, the use of such over-represented signals spaces in mechanism design (that is using a report space that is strictly bigger than the signal type space) is novel, through the literature is vast, so we are not certain. The closest to our knownledge is in 



