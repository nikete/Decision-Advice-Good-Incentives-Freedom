%!TEX root = main.tex
% optimal decision elicitiation algorithm

Consider a setting with multiple experts providing advice to a subject, who wishes to incentivize them to inform them of which of a set of available actions maximize the reward.
One natural way to attempt to do is by applying the machinery of prediction markets based on sequentially shared proper scoring rules, and only settlign the markets where actions are taken. Doing this in an incentive compatible manner for the experts is however incompatible with maintaining the subjects freedom to select the action that appears optimal ex-post (\cite{othman2010decision,  chen2014eliciting}, that is using the max decision rule. 
The core of the problem with using the machinery of prediction markets in the decision setting is that at the point where the mechanism has correct belief over the optimal action but not others, a expert  can profit by changing expected rewards to make optimal action appear worse than an action for which the expected reward can be corrected.


The guiding design criterion in this work is to restrict as little as possible the decision that the subject must take (maximizing their freedom) while still providing good incentives to the experts. No previous mechanisms in the literature can truthfully aggregate arbitrary signals over many experts in BNE. 

We first focus on a direct mechanism. Experts directly report their signals to the mechanism, which then uses them to compute the optimal action given the prior to output to the subject. This requires  the experts and the mechanism having access to a common bayesian prior, over the joint probabilities of the rewards, true signals, the output action and the response of the subject to a given output of the mechanism. There is a BNE that aggregates all information over $N$ experts, unlike the case in the previous mechanisms in the literature.
We then analyze a simple bid based variation of the mechansim, and provide a sufficient conditions on the signal structures where information can be fully aggregated; we further show that these conditions are sufficient to make truthfulness dominant incentive compatible.  



\section{Model}

We consider a single subject with access to $K$ possible choices, their outcomes are sufficiently characterized for the subject by a reward vector $R$ which is unobservable to the subject, where each element in $r_k$ corresponds to the reward the subject receives if he carries out the corresponding action in $K$ . We consider a set of $N$ experts, each of whom have access to some signal $s_i$ which are potentially informative about $E[e|a,c]$, we use $S$ to denote the vector containing all signals.  $P$ denotes a prior distribution over $P(R|S) $ which is common knowledge.

To map to the mechanism design literature the $P$ would be over states of the world in $\Omega$ and each state of the world consists of a agent type (complier probability and action outcome and the value a utility functin placed on it, which equates to rewards in our notation) and the signals of each expert.

A mechanism anounces a payment rule $p_i(\hat{s}, c,a,r)$, with $p_i$ being the payment to expert $i$, with $\hat{s}$ being the reported signals, $\hat{c}$, and by $c^{*}$ the reward maximizing choice given the true signals.
Each experts receives their signals $s_i$, and makes a reports $\hat{s}_i$ to the mechanism, which outputs a chosen action $c^{*}$.
The subject observes the action chosen by the mechanism $\hat{c}$, and takes a (potentially different) action $a$. A reward $r$ is observed, and the mechanism makes the corresponding payments.

An experts $i$ report is truthful when $\hat{s}_i=s_i$. A mechanism is incentive compatible when truthful reports maximize the payment experts receive and this holds for all experts. This can be in dominant strategies or in a bayesian nash equilibrium.  We seek efficient mechanisms, that is $c^{*} = \hat{c}$ for all posible signals.



\section{Shared Reward Mechanism}

Here we explore a set of mechanisms based around the idea of sharing the rewards from the taken action with the experts.

\subsection{Share of Reward Mechanism}

Let us first consider a very basic direct mechanism, which will help us understand the model and the limitations that subjects freedom imposes. 
A simple mechanism that is strictly incentive compatible (in equilibrium) for an expert to reveal their signal when subjects are utility maximizers is to give all experts a share of the reward. Equivalently (in expectation) run a lottery after the reports are submitted that assigns a share of the reward to the expert that wins. 

In this case the signals may be arbitrary, the payment rule is invariant to them, and defined as $\pi_i  = (\alpha / N ) r $ with $\alpha < 1$. Note that we are not defining the payment rule to be conditional on the subjects actual action in any way. %In particular, it might naively seem appropiate to only give the share when the chosen action is the actual action carried out. 


\subsubsection{Limitations}
This mechanism is problematic in a number of ways

\begin{itemize}
\item it pays out even when experts signals are useless.
\item the entry of useless experts reduces the payment received by valuable ones or the budget needed by the mechanism.
\end{itemize}

Somewhat more formally we say a expert is useless, if where the expert able to force the action to be his choice, he would not improve the expected reward beyond picking the action that is the max expected utility in the common prior.

This motivates considering the next mechanism.


\section{Freedom and Limits to Defiance}

If we consider subjects with potentially unrestricted freedom, i.e. subjects are not necesarily expected reward maximizers, then the mechanism is not necesarily truthful, even for a single expert. 

\begin{eg}[total freedom yields bad incentives for a single expert]
	For example, consider a subject that has a prejudice in favour of treatment A, and so will take it unless the expected reward of treatment B is more than 10 utils highers. Consider a expert with access to a signal wich is an unbiased estimate of the rewards over both actions, receives a signal  that B reward is higher by 9 utils. The expert is strictly better off reporting that his signal has B as more than 10 better.
\end{eg}

\begin{eg}[subjects who defy experts yield perverse incentives]
	More generically we can consider of an agent who does the oposite of what maximizes reward (the min decision rule), this creates incentives for experts to flip the ordering that their signals imply. 
\end{eg}

Thus, it can be seen that providing unrestricted freedom in the broadest sense to subjects makes the setting hopeless. 

One restriction on subjects freedom that is sufficient to allow (in the single expert setting) dominant strategy truthful mehcanism is \emph{no defiers}: assuming that all subjects are either utility maximizers (compliers) or have some action they will take irrespective of the reports of the experts (always takers or never takers in the binary setting).
This preserves substantial freedom, in that it is not required the subject known a priori that they will compliers, their realization of the always taker type could come after the mechanism has been run and before the action is taken. 

This can be somewhat relaxed, since the needed property it implies is that the mechanism choosing an action with higher expected reward if actually carried out leads to the expected reward conditional on the chosen action to be higher. Formally the condition that is sufficient (\NDP{necesary?})
$$E[ ^{*}|c_i]  \geq E[ r^{*}|c_j] \text{ if }E[ ^{*}|a_i]  \geq E[ r^{*}|a_j]  \forall j \neq i \in K$$
Note that under this assumption existing mechanisms for the many expert setting are not incentive compatible unless subjects can credibly commit to using a randomized strategy which places positive mass on dominated action (i.e. there are no ex-post incntive compatible mechanisms based on proper scoring rules and voiding given a no defiers assumption):



There is some extra flexibility more than no defiers which we should use, for example differential compliance rates for different actions, the mechanisms selects the action that most raises the reward not the one who has the highest reward (for example an action that has the second highest reward but 1\% noncompliance might be chosen instead of one  that has 99\% noncompliance and the highest reward. No defiers buys us the extra part that chosen is the highest reward action, so makes life easier for the subject (if the noncompliance depended on the signals the expert receives a utility maximizing decision maker would have to consider other decision markets noncomplaince characteristics in the prior before deciding how to interpret the chosen action; this removes such ambiguities and doesn't seem to loose too much generality)



\section{Limits of Sequential Scoring Rule and Void Decision Markets}

\begin{eg}[under SSRDM with a utitlity maximizing subject an expert can always benefit from exaggerating the success probability of a suboptimal action]
	counterexample from \cite{othman2010decision}
\end{eg}


\NDP{Having the first theorem in a paper seems less than ideal, maybe we can instead state the following corollary which reexpresses it in our terms?} \DBA{I don't understand the words before ``less than ideal''.}

Further, an immediate corollary to a theorem X of \cite{chen2014eliciting} 
 which states that Randomized decision rules with full support are necesary for incentive compatible  scoring rule decision markets (SRDM) is : If a subject is free to either maximize their expected utility at decision time, or can have probability zero of taking some actions, then a SRDM is not IC for them.




\section{A Direct VCG style mechanism for optimal decision elicitation }
Given these desires and the limitation of the existing mechanism we take a approach inspired by direct VCG-style mechanism.

All agents know a common prior that gives full probability distribution of rewards over all posible signals, chosen actions and actual actions.

For each expert $i$, compute the optimal action to choose without using that experts report (i.e. marginalizing over the prior on signal $i$ signal), denote this action $\hat{c}_{-i}$ and it's expected reward 

$E[\hat{r}_{-i}] = E[ r| \hat{c}_{-i}, \bigcup \hat{s}_j  \forall j \neq i \in N]$ \NDP{is there a better way to notate this conditioning on the information in all the other signals than the experts? maybe $S_{-i}$ to denote the joint signals off all the others?} \DBA{I've seen $S_{-i}$ and $S_{\hat{i}}$ used}


 The payment rule is announced as follows:

\[
    \pi_i = 
\begin{cases}
    r - E[\hat{r}_{-i}] ,& \text{if } \hat{c}_{-i} \neq c\\
    0,              & \text{otherwise}
\end{cases}
\]


Each expert reports their signal, the mechanism calculates the action that maximizes the reward, $c$ and chooses it. After observing the actual action taken $a$ and its reward $r$ the payments are made, this concludes the mechansim.

Note that conditional on the action taken and the payments do not depend on the reported signal of agent $i$ if we hold fixed the chosen action. 

\begin{lem}
	the only way a experts reports affects their payments is via the chosen action.
\end{lem}

\begin{eg}[redundant experts]
	If you have two experts and they both observe and report the same signal, they both get outcome zero. 
\end{eg}


\begin{lem}
	useless experts cannot profit from participation
\end{lem}

this is inmidiate from hwo the payment rule and useless experts are defined, since if there is no ifnromation to raise r and that is all tha that can lead to 

\subsection{Incentive Compatibility and Efficiency}


\begin{defn}[Bayes-Nash Incentive Compatibility]
	A BNE where all experts truthfully report their signals.
\end{defn}

There is a  equilibrium where all experts maximize their payment by maximizing the probability that the action with the highest reward is taken; if all other reports are truthful and under a no defiers assumption then this is optimized by being truthful.

\begin{proof}
For a given expert $i$ let all other experts report truthfully, then substituing in the true signals into the reports the expert faces 


\[
    \pi_i = 
\begin{cases}
    r(a) -  E[ r| c_{-i}, \bigcup s_j  \forall j \neq i \in N] ,& \text{if } \hat{c}_{-i} \neq c\\
    0,              & \text{otherwise}
\end{cases}
\]

thus the only thing his report will affect in his payment is $r(a)$ via the choice of $a$, given all other experts are truthful then by construction if he is truthful this will select the $a$ that maximizes $r$. Thus truthfulness is a BNE.

\end{proof}

\subsection{Potential Negative Expetation for Subject}
Payments can be more than the improvement in the reward the mechanism creates \NDP{This is standard of VCG style stuff; we are getting efficiency and truthfulness, so the payments dont work out or the mechanism isnt voluentary}. 


\begin{eg}[expensive experts]
	Let there be two experts, two actions ${\alpha,\beta}$ and four equal probability states of the world, ${A,B,C,D}$, with payoffs to the actions correspondingly as ${(0,1),(0,-1),(-1,0),(1,0)}$. Let one expert oberve that they are in either ${A,B}$ or ${C,D}$ and the other ${B,C}$ or ${A,D}$. A uniform random strategy achieves an expected value of 0. An optimal strategy with access to a single expert (either one) achieves a value of 0. Using the signals of both we can achieve reward 1. Thus the VCG payments are $1$ to each, and the mechanism improves the subjects welfare by $1$ while making $2$ in payments, thus $-1$. 
\end{eg}

\DBA{Checked}



\section{Bounded Payments}
As presented the direct VCG mechanism might have unbounded payments (if there are states of the world with sufficiently high reward differentials and a sufficiently large number of experts with complementary signals) and thus the subject might be better off not participating a priori. Here we introduce a variation on the mechanism that re-scales payments using the prior so they are bounded.


\DBA{Provide argument that the rescaling component of the mechanism cannot be gamed}

\NDP{This might not be possible. see http://web.stanford.edu/~jacksonm/mechtheo.pdf }

\DBA{this worries me. If rescaling can be gamed, then we need some other way to guarantee the mechanism is always of value to the subject.}

\begin{eg}[bounding payments mechanism]

Let $E[r|c(s)]$ denote the expected reward obtained from choosing the optimal action using all signals if they where reported truthfully, and $E[r|c(p)] $ the expetec treward from picking the action using only the prior and no singals. Thus $E[r|c(s)] - E[r|c(p)] $ is the expected surplus from using the information in a truthful mechanism relative to using only the priors. Let $alpha$ be a constant bellow zero, and consider scaled payment of agent $i$ as 

\[
  \rho_i  = ( \pi_i  / \sum \pi_{-i} )    \alpha  (E[r|a(s)] - E[r|a(p)] 
\]

while this guarantees we never pay more than alpha share of the benefit, it is gamable. in particular the experts report now affects his payout beyodn the chosen action by affecting the payout of the other agents before scaling ($\sum \pi_{-i}$).

\end{eg}




\begin{lem}
	the rescaling component of the mechanism cannot be gamed
\end{lem}





the experts have to have the potential for negative payoffs (even through the expected payoff in equilibrium is positive). Since the mchanism stoping the payments around zero would change the expectation. 





\begin{defn}[Dominant Strategy Truthfulness]
	ftw
\end{defn}

The incentive compatibility here is only in one nash equilibrium, and not in dominant strategies. In particular, if another expert does not report their signal truthfully, an expert might maximize the reward by making a countervailing report that is not truthful, to cancel out the other untruthful expert. 

\begin{eg}[mechanism is not dominant-strategy incentive compatible]
	Consider a setting with a reward maximizing subject with probability 1, two possible actions, where two experts know with certainty that the rewards are $1,2$ and one of them reports $1,0$. A truthful report would lead to choosing the first action (the average of the two reports) with rewards of $1$ while a report of $0,2$ would cause the max to select the seccond action and obtain a reward of $2$.
\end{eg}

Also note that the payout to the in this example to the expert is positive it can triviall be made negative, so the expert does not make the countervailing report as it wouldnt maximize their payment; for example if the untruthful agent reports was $3,0$.

\begin{con}
	No mechanism can get around this (intuition; we are tyring to get as close to vcg as possible, and i dont see a way to get closer).
\end{con}
\DBA{proving a negative is hard; e.g. this paper is circumventing Chen's negative result}

\subsection{A sufficient condition for dominat truthfulness in reports}

in general the mechanism is not dominant truthful, since a trickster agent who inverts their reporrts would make the other agents try to compensate if possible, as seen above.
If the action chosen depends only on the signal of the highest type, (the type whose signal without using he other signals implies the highest reward for the optimaly chosen action) 

To see this, note that bidding the valuation conditional on their signal and winning is domminant strategy in the 

\subsection{Noncompliance and Incentive Compatibility}

For the same reassonsas before there is no dominant strategy incentive compatibility. 

A interesting question that arrises is how to handle the case where the action that is optimal given the reports is not the actual chosen action. Three natural strategies are:

\begin{itemize}
\item make payments irrespective. \DBA{I realized here that you're using (1) received payoff instead of (3) expected payoff. This seems problematic. E.g. if noncompliance leads to lower reward (which is presumably to be expected if experts know more than subject) then experts' payouts take a hit based on subject's capriciousness. This is especially problematic if payouts are negative due to subject's noncompliance.}
\NDP{I initially tried setting to void market if action nto followed, but this creates perverse incentives, where the subject might not follow the advice and receive a lower payoff to avoid payment. While your statements abotu the experts are true they (A) the prior taking into account noncompliance makes these expectations workable, you take into account the fact that some advice might not be followed with higher probability. (B) the \emph{no defiers} (terrible name, sinc eit is even stronger than that, uniform noncompliance might be a better term), is a sufficient condition to rule this out.}

\item make the payment for the $\beta r_a$ but do not require the payment of $b_{i-1}$.
\item make no payment, and require no payment.
\end{itemize}

Only the first is incentive compatible. TODO: formalize. Sketch: a crucial property is that w separate bids and reports, this lets the reports be truthful while the bids are shaded (as is standard in common value seccond price auction). Further, it means that noncompliance (given the no defiers assumption) 
\DBA{maybe I'm missing something. But if the subject has a strong tendency to pick low-reward actions, then the experts are disincentivized from providing any advice at all, since they will likely receive negative payouts}
\NDP{The prior is over the noncompliance (what you are terming it the tendency to pick low actions here) }


If we do not require the payment, it can incentivize experts to report in such a way as to encourage non-compliance, since this would increase their payout. \DBA{example}
If we void the payment completely this can have the oposite effect, biasing experts away from reporting the \DBA{Is this paragraph dependent on agent's having a model of the subject's noncompliance? E.g. If subject's noncompliance is random (ignore advice with probability $p$ and then pick action uniformly), are the second and third options incentive compatible?}




\section{The signal reporting vcg mechanism can work even when utilities are not part of the common prior}

the mechanism, but not necesarily the experts, needs access to the utility function of the decision maker and the prior over which expectations are taken 

\DBA{does the utility function of the decision maker (along with prior) ``explain'' its noncompliance? This is somehow a conceptual question, not sure if it makes a difference to the meat of the paper. }

for a cancer example; the chemiotherapy specialist might explain the likely side effects conditional on their knowledge of the specifics of the patient (the rapidly dropping cost of sequencing a genome means this) without needing to understand the relative value the patient places on discomfort relative to life lengthening, while the surgeon might explain the (again subject tot he specific characteristics of the subject) risks he foresees in the surgury (in contrast to the baseline risks of the populatin that gets the procude which is what cna be observed, a reasoable prior) for that patient, without needing to udnerstand the risk aversion of the patient which would be necesary for calculating their utility.

the subject (oracle style) can then be queried for their chosen action and expected utility for different subsets of the signals (for every expert we need to query what the action (and the expected payoff) would be without that experts signal having been reported)

contrast the information structure in the cancer example and its non separability 


\section{A bidding mehcnaism }

In many practical applications of interest, it might be that the signals can't be practically reported. For example, because while the expert knows something when they see it, they do not have a vocabulary to unambigously express it. 


If we replace the reports in the direct mechnaism by bids, and we allow the winner of the auction to pick the action, we have a mechanism that doesnt make any strong assumptions beyond that the agents understand the rules of the game.

For some information structures this still aggregates information well, for example:

\begin{lem}[specialist experts]
	if each expert knows the exact outcome conditonal on one action and knows he doesnt know what happens under other actions, and there is at least one expert that is informaed about each action.
\end{lem}

For other information structures it does not work, for exmaple 
\begin{eg}
	the classic example without separability that fails in the bayesian games so broadly (TODO Add cite) also fails here. 
\end{eg}

%\section{Summary}

\subsection{Interpreting bids}

the bids reflect the expected value of the mechanism choosing a particular action, not of that action being taken. \DBA{I'm confused. In previous section, ``each expert knows the exact outcome conditonal on one action'', and now its conditional on action being chosen, not taken. These sentences sentences seem to be at odds.} Example: if half are allways takers, the bid effectively waters down the true effect by half.
\DBA{So the bids made by experts depend on the expert's model of the subject's behavior?}

further, due to the winners curse, it is the expected effect conditional on having won the auction. 
\DBA{can you write down how expected conditional on having won is computed?}

\DBA{At this point, the interpretation of the bid has been qualified twice, and I'm lost}

\subsection{A sufficient separability condition for efficiency}

if each expert knows the value of a action the MSR and Void mechanism in the style of Hanson fail to be myopically incentive compatible when agents always follow the action whose price is maximal in the market (\cite{othman2010decision})



\section{Tradeoff between Dominant Strategy Incentive Compatible and Expressivity}



\subsection{A sufficient condition}

when the expert who won the auction selects and action, particularly in the early rounds she might be doing it becuase he wishes to explore, and thus the incentives 

