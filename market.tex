%!TEX root = main.tex
% optimal decision elicitiation algorithm

Consider a setting with multiple experts providing advice to a subject, who wishes to incentivize them to inform them of which of a set of available actions maximize the reward.
One natural way to attempt to do is by applying the machinery of prediction markets based on sequentially shared proper scoring rules, and only settlign the markets where actions are taken. Doing this in an incentive compatible manner for the experts is however incompatible with maintaining the subjects freedom to select the action that appears optimal ex-post (\cite{othman2010decision,  chen2014eliciting}, that is using the max decision rule. 
The core of the problem with using the machinery of prediction markets in the decision setting is that at the point where the mechanism has correct belief over the optimal action but not others, a expert  can profit by changing expected rewards to make optimal action appear worse than an action for which the expected reward can be corrected.


The guiding design criterion in this work is to restrict as little as possible the decision that the subject must take (maximizing their freedom) while still providing good incentives to the experts. No previous mechanisms in the literature can truthfully aggregate arbitrary signals over many experts in BNE. 
We first focus on a direct efficient mechanism in the style of VCG mechanism. Experts directly report their signals to the mechanism, which then uses them to compute the optimal action given the prior to output to the subject. This requires  the experts and the mechanism having access to a common bayesian prior, over the joint probabilities of the rewards, true signals, the output action and the response of the subject to a given output of the mechanism. There is a BNE that aggregates all information over $N$ experts, unlike the case in the previous mechanisms in the literature.
We then analyze a simple bid based variation of the mechansim, and provide a sufficient conditions on the signal structures where information can be fully aggregated; we further show that these conditions are sufficient to make truthfulness dominant incentive compatible.  




\section{Model}

We consider a single subject with access to $K$ possible choices, their outcomes are sufficiently characterized for the subject by a reward vector $R$ which is unobservable to the subject, where each element in $r_k$ corresponds to the reward the subject receives if he carries out the corresponding action in $K$ . We consider a set of $N$ experts, each of whom have access to some signal $s_i$ which are potentially informative about $E[e|a,c]$, we use $S$ to denote the vector containing all signals.  $P$ denotes a prior distribution over $P(R|S) $ which is common knowledge.

To map to the mechanism design literature the $P$ would be over states of the world in $\Omega$ and each state of the world consists of a agent type (complier probability and action outcome and the value a utility functin placed on it, which equates to rewards in our notation) and the signals of each expert.

A mechanism anounces a payment rule $p_i(\hat{s}, c,a,r)$, with $p_i$ being the payment to expert $i$, with $\hat{s}$ being the reported signals, $\hat{c}$, and by $c^{*}$ the reward maximizing choice given the true signals.
Each experts receives their signals $s_i$, and makes a reports $\hat{s}_i$ to the mechanism, which outputs a chosen action $c^{*}$.
The subject observes the action chosen by the mechanism $\hat{c}$, and takes a (potentially different) action $a$. A reward $r$ is observed, and the mechanism makes the corresponding payments.

An experts $i$ report is truthful when $\hat{s}_i=s_i$. A mechanism is incentive compatible when truthful reports maximize the payment experts receive and this holds for all experts. This can be in dominant strategies or in a bayesian nash equilibrium.  We seek efficient mechanisms, that is $c^{*} = \hat{c}$ for all posible signals.


\section{A Simple Reward Sharing Mechanism}

Here we explore a set of mechanisms based around the idea of sharing the rewards from the taken action with the experts.

Let us first consider a very basic direct mechanism, which will help us understand the model and the limitations that subjects freedom imposes. 
A simple mechanism that is strictly incentive compatible (in equilibrium) for an expert to reveal their signal when subjects are utility maximizers is to give all experts a share of the reward. Equivalently (in expectation) run a lottery after the reports are submitted that assigns a share of the reward to the expert that wins. 

In this case the signals may be arbitrary, the payment rule is invariant to them, and defined as $\pi_i  = (\alpha / N ) r $ with $\alpha < 1$. Note that we are not defining the payment rule to be conditional on the subjects actual action in any way. %In particular, it might naively seem appropiate to only give the share when the chosen action is the actual action carried out. 

\subsubsection{Limitations}
This mechanism is problematic in a number of ways

\begin{itemize}
\item it pays out even when experts signals are useless.
\item the entry of useless experts reduces the payment received by valuable ones or the budget needed by the mechanism.
\end{itemize}

Somewhat more formally we say a expert is useless, if where the expert able to force the action to be his choice, he would not improve the expected reward beyond picking the action that is the max expected utility in the common prior.

This motivates considering the next mechanism.


\section{Freedom and Limits to Defiance}

If we consider subjects with potentially unrestricted freedom, i.e. subjects are not necesarily expected reward maximizers, then the mechanism is not necesarily truthful, even for a single expert. 

\begin{eg}[total freedom yields bad incentives for a single expert]
	For example, consider a subject that has a prejudice in favour of treatment A, and so will take it unless the expected reward of treatment B is more than 10 utils highers. Consider a expert with access to a signal wich is an unbiased estimate of the rewards over both actions, receives a signal  that B reward is higher by 9 utils. The expert is strictly better off reporting that his signal has B as more than 10 better.
\end{eg}

\begin{eg}[subjects who defy experts yield perverse incentives]
	More generically we can consider of an agent who does the oposite of what maximizes reward (the min decision rule), this creates incentives for experts to flip the ordering that their signals imply. 
\end{eg}

Thus, it can be seen that providing unrestricted freedom in the broadest sense to subjects makes the setting hopeless. 

One restriction on subjects freedom that is sufficient to allow (in the single expert setting) dominant strategy truthful mehcanism is \emph{no defiers}: assuming that all subjects are either utility maximizers (compliers) or have some action they will take irrespective of the reports of the experts (always takers or never takers in the binary setting).
This preserves substantial freedom, in that it is not required the subject known a priori that they will compliers, their realization of the always taker type could come after the mechanism has been run and before the action is taken. 

This can be somewhat relaxed, since the needed property it implies is that the mechanism choosing an action with higher expected reward if actually carried out leads to the expected reward conditional on the chosen action to be higher. Formally the condition that is sufficient (\NDP{necesary?})

%TODO $$E[ ^{*}|c_i]  \geq E[ r^{*}|c_j] \text{ if }E[ ^{*}|a_i]  \geq E[ r^{*}|a_j]  \forall j \neq i \in K$$
Note that under this assumption existing mechanisms for the many expert setting are not incentive compatible unless subjects can credibly commit to using a randomized strategy which places positive mass on dominated action (i.e. there are no ex-post incntive compatible mechanisms based on proper scoring rules and voiding given a no defiers assumption):

There is some extra flexibility more than no defiers which we should use, for example differential compliance rates for different actions, the mechanisms selects the action that most raises the reward not the one who has the highest reward (for example an action that has the second highest reward but 1\% noncompliance might be chosen instead of one  that has 99\% noncompliance and the highest reward. No defiers buys us the extra part that chosen is the highest reward action, so makes life easier for the subject (if the noncompliance depended on the signals the expert receives a utility maximizing decision maker would have to consider other decision markets noncomplaince characteristics in the prior before deciding how to interpret the chosen action; this removes such ambiguities and doesn't seem to loose too much generality)



\section{Scoring Rule and Void Decision Market Mechanisms}

An attempt to adapt Market Scoring Rules prediction markets to the decision setting (see background chapter for details) which might be termed Scoring-rule and Void Decision Market Mechanisms (we will abreviate to SVDM). The basic idea is to use a sequentially shared proper socring rule to run a prediction market for the value of the reward conditional each possible action, and to void the markets for the non-chosen actions.  


\begin{eg}[With a utitlity maximizing subject an expert can benefit from exaggerating the success probability of a suboptimal action]
	Example from \cite{othman2010decision}
\end{eg}


\NDP{Having the first theorem in a paper not be one of the main theorems of the paper seems less than ideal, maybe we can instead state the following corollary which reexpresses it in our terms?} \DBA{I don't understand the words before ``less than ideal''.} \NDP{Sorry, id acidentally cutted off some text there. Now is fixed.}

Further, an immediate corollary to a theorem X of \cite{chen2014eliciting} which states that Randomized decision rules with full support are necesary for incentive compatible SVDM mechanisms:

If a subject is free to either maximize their expected utility at decision time, or can have probability zero of taking some actions, then a SRDM is not IC for them.



\section{A Direct Mechanism for Efficient Optimal Choice Elicitation}

We now consider a VCG style mechanism for the optimal decision elicitation problem. The sense in which it is VCG is that it is efficient (always chooses the action whose choice maximizes rewards, note this can be different form the actual action which if carried out with perfect compliance would do so) and we compensate subjects for the extenrality their signal imposes; since truthful reports cannot by definitiion lower the expected value of the optimal action relative to having chosen the action without using the extra signal, these are strictly positive when all reports are truthful. 

Our use of received payoff instead of expected payoff avoids the use of counterfactual. This seems problematic. For example, if noncompliance leads to lower reward (which is presumably to be expected if experts know more than subject) then experts' payouts is reduced due to a subject's capriciousness. 

This is especially problematic if payouts are negative due to subject's noncompliance.
\NDP{I initially tried setting to void market if action nto followed, but this creates perverse incentives, where the subject might not follow the advice and receive a lower payoff to avoid payment. While your statements abotu the experts are true they (A) the prior taking into account noncompliance makes these expectations workable, you take into account the fact that some advice might not be followed with higher probability. (B) the \emph{no defiers} (terrible name, sinc eit is even stronger than that, uniform noncompliance might be a better term), is a sufficient condition to rule this out.}

All agents know a common prior that gives a proper prior probability distribution of rewards over all posible signals, chosen actions and actual actions.

\begin{mech}\label{mech:vcg-style}[Efficient VCG-style Mechanism]


%$\hat{S}_{-i} = \bigcup \hat{s}_j  \forall j \neq i \in N $ then the expected reward given the others reports is:

For each expert $i$, compute the optimal action to choose without using that experts report (i.e. marginalizing over the prior on signal $i$ signal), denote this action $\hat{c}_{-i}$ and it's expected reward:

$E[\hat{r}_{-i}] = E[ r| \hat{c}_{-i}, \hat{S}_{-i}] $


 The payment rule is announced as follows:

\[
    \pi_i = 
\begin{cases}
    r - E[\hat{r}_{-i}] ,& \text{if } \hat{c}_{-i} \neq c\\
    0,              & \text{otherwise}
\end{cases}
\]

%

Each expert reports their signal, the mechanism calculates the action that maximizes the reward $c$, and chooses it. After observing the actual action taken $a$ and its reward $r$, the corresponding payments are made, this concludes the mechansim.

Note that conditional on the action taken and the payments do not depend on the reported signal of agent $i$ if we hold fixed the chosen action. 

\end{mech}

Note, if you take out the if and reward players no matter what, all you do is increase the variance but dont change the expectation. The  mechanism and its properties still hold under risk neutral expert,  this is because the expected reward when using all signals and when using only the other agents signals has to be the smae if the same action is being taken. 


\begin{lem}\label{lem:affect}
	The only way an expert's report affects their payments is via the chosen action.
\end{lem}

\begin{proof}
There are two terms in the expression for the payment rule $\pi_i$: the received reward $r$ and expected reward $E[\hat{r}_{-i}]$ given the counterfactual that expert $i$ is ignored. 
The first term is the reward received after executing the chosen action, and therefore clearly only depends on the chosen action. 
The second term is explicitly constructed so as not to use the report by expert $i$. 
\end{proof}

\begin{lem}[redundant experts]
	Two experts report the same signal, they both get payoff zero. 
\end{lem}


\begin{lem}
	Useless experts cannot profit from participation
\end{lem}

\begin{proof}
This is inmidiate from how the payment rule and useless experts are defined, since by definiion there is no information that can be reported to raise $r$ and that is all that can lead to higher rewards.
\end{proof}

%TODO pin down useless more formally still

\subsection{Incentive Compatibility and Efficient}

\begin{thm}[Bayes-Nash Incentive Compatibility]
	A Bayes Nash Equilibrium exists where all experts truthfully report their signals.
\end{thm}

There is an equilibrium where all experts maximize their payment by maximizing the probability that the action with the highest reward is taken; if all other reports are truthful, and under a no-defiers assumption, then this is optimized by being truthful.

\begin{proof}
For a given expert $i$, let all other experts truthfully report their signals. By Lemma~\ref{lem:affect}, the only effect an expert has on their payment is via their effect on the chosen action $c$. Given all other experts are truthful, it follows by the definition of Mechanism~\ref{mech:vcg-style} that if expert $i$ is also truthful then the mechanism will select the $c$ that maximizes the expected $r$, thus maximizing the expert $i$'s reward. Truthfulness is therefore a Bayesian Nash equilibrium.
\end{proof}

\subsection{Potential Negative Expetation for Subject}

Payments can be more than the improvement in the reward the mechanism creates.

\begin{eg}[expensive experts]
	Let there be two experts, two actions ${\alpha,\beta}$ and four equal probability states of the world, ${A,B,C,D}$, with payoffs to the actions correspondingly as ${(0,1),(0,-1),(-1,0),(1,0)}$. Let one expert oberve that they are in either ${A,B}$ or ${C,D}$ and the other ${B,C}$ or ${A,D}$. A uniform random strategy achieves an expected value of 0. An optimal strategy with access to a single expert (either one) achieves a value of 0. Using the signals of both we can achieve reward 1. Thus the VCG payments are $1$ to each, and the mechanism improves the subjects welfare by $1$ while making $2$ in payments, thus $-1$. 
\end{eg}




\section{Scaling Payments and Rational Entry}

As presented the VCG style direct mechanism can have higher payments than the benefits it provides in terms of higher rewards (if there are states of the world with sufficiently high reward differentials and a sufficiently large number of experts with complementary signals). Hence, the subject might be better off not participating \emph{a priori}. Here we introduce a variation on the mechanism that re-scales payments using the prior so a subject \emph{a priori} wishes to participate in the mechanism. The mechanism takes advantage of two observations. Firstly, one can set $\alpha$ prior to receiving signals from experts based on the prior. Secondly, by Lemma~\ref{lem:affect} experts do not care about the chosen action beyond how it affects their payments. 

The second observation does not hold in standard VCG mechanisms: if they cared about the action then you need to compensate them exactly for their externality. While this doesn't make an explicit appearance in the proof it is the reason why we can scale the payments to alter the budget in a way that VCG mechanisms cannot: a change in the allocation that leaves payments unchanged alters the utility of agents in the VCG setting but not here, so the payments in the VCG setting have to move to counter-balance this precisely, limiting the freedom with which we can choose them.

\NDP{Explain relation to the  Clarke pivot rule. With the Clarke pivot rule, the total amount paid by the player is: (social welfare of others if i were absent) - (social welfare of others when i is present).
This is exactly the externality of player  i}

In the model we have presented a expert pays no cost when aquiring their signals, and so in the single agent case the payment made by the subject for signals can in principle be arbitrarily close to zero while still incentivising truthful reports (for example the share of the reward mechanisms achieves this). We now study when payments rules can be scaled to create ex-ante in expectation arbitrarily small expected payments to the experts. As usual, we assume risk neutral experts. 



Let $E[r|c(s)]$ denote the expected reward obtained from choosing the optimal action using all signals if they where reported truthfully, and $E[r|c(P)] $ the expected reward from picking the action using only the prior and no signals. Thus $E[r|c(S)] - E[r|c(P)] $ is the expected surplus from using the information in the truthful equilibrium of the mechanism relative to using only the priors. For an efficient mechanism to be rational \emph{a priori} for the subject to implement, it must be that $E[r|c(S)] - E[r|c(P)] > E[\sum \pi]$ where $\pi$ is either the result of a Nash equilibrium or a dominant strategy (i.e. we set all elements of $\hat{s}$ jointly to maximize $\sum \pi$, even if this does not a equilirium for the experts).

Note that a constant afine transformation of the rewards preserves the incentives. Denote by $\alpha$ that scales the payment.

\begin{mech}[Cheap and Efficient Mechanism]

The value of $\alpha$ can be chosen \emph{a priori} based on $P$ such that: $ E[\sum \rho_i] < E[r|c(s,P)] - E[r|c(P)] $. 

%\NDP{TODO spell out how. This seems like it should be just algebra, for exmaple if aprior I expect 10 complementary signals which combined produce a expected surplus of 1 then i want to have $g = \alpha pi$ and $\alpha < 1/10$. How can we make this procedure generic? }

\[
  \rho_i  = \alpha \pi_i
\]

\end{mech}

\NDP{Initiall I tried instead of just a multiplier $< 1$, having a gneeral function $g$ with $g(0) = 0$, and $g$ is monotonically increasing in $p_i$. But this doesnt work if you lower the negatives more than the positive for example you fuck up the payments. Do we prove the scaling has to be a multiplicative, an aditive breaks it (if positive cnat help with budget and if negative can cause it to be irational for experts to enter if expected value of expert is bellow, while non linear transformation instead of linear multipler doesnt preserve the expectations and tus can also break the incentives of the experts to be truthful)
}

\begin{lem}
	The rescaling of the mechanism preserves the incentives of experts
\end{lem}

\begin{proof}
	As they are set apriori based on expectations only, $\alpha$ is invariant to any reports the experts make. Since the transformation is afine, whatever report maximizes payoffs remains unchanged. Since 
\end{proof}


\begin{lem}
	Entering the mechanism is positive expectation for the subject.
\end{lem}

\begin{proof}
  By construction$ \alpha $ is picked such that $E[\sum \rho_i] < E[r|c(s,P)] - E[r|c(P)]$
\end{proof}


\begin{lem}
	Entering the mechanism is (weakly) positive expectation for the experts in the revelation BNE.
\end{lem}

\begin{proof}
Since a truthful signal cannot lower (if all other signals are being reported truthfully) the expected reward of the optimal chosen action and the transformation of the payoff is linear, and the expert always has the option of reporting their true signal, the expected return in the revealing BNE of entering is weakly positive.
\NDP{Do it in algebra?}
\end{proof}


\begin{thm}
	the scaled efficient mechanism is individualy rational for all agents, experts and subject.
\end{thm}

\begin{proof}
inmidiate from the two previous lemmas, since the subject and experts are all the agents involved.
\end{proof}




\section{Dominant Mechanisms}

\begin{defn}[Dominant Strategy Truthfulness]
	A Mechanism and Prior Signal Distribution are \emph{Dominant Strategy Truthfull} for an expert if reporting their true signal maximizes their expected payoff for any set of reports by the other agents. 
\end{defn}

The incentive compatibility in the previous section is only a bayes nash equilibrium, and not a dominant strategies. In particular, if another expert does not report their signal truthfully, an expert might maximize the reward by making a countervailing report that is not truthful, to cancel out the other untruthful expert. 

\begin{eg}[mechanism is not dominant-strategy incentive compatible]
	Consider a setting with a reward maximizing subject with probability 1, two possible actions, where two experts know with certainty that the rewards are $1,2$ and one of them reports $1,0$. A truthful report would lead to choosing the first action (the average of the two reports) with rewards of $1$ while a report of $0,2$ would cause the max to select the seccond action and obtain a reward of $2$.
\end{eg}


\subsection{A sufficient condition for dominat truthfulness of an expert in efficient mechanisms}

In general the efficient\footnote{Mechanisms that are not efficient are trivial to make weakly dominant strategy truthful. For example disrewarding reports always picking an arbitrary action} mechanism is not dominant strategy incentive compatible, since (for example) a expert agent who inverts their reporrts would make the other experts also misreport try to compensate if possible, as seen in the example above.

Consider a experts \emph{unilateral value}, the expected value of pickign the optimal action conditional only on their signal, which we denote by  $E[ r| c_{i}]$. A \emph{unilaterally sufficient expert} is one where $E[r|c_{i}] \geq E[r|c_{s_i \cup s_{-i}}] \forall s_{-i}$, that is the experts signal pins down a choice of action that obtains expected optimal rewards irrespective of any other possible signal received by the other experts.

\begin{lem}
	A unilaterally sufficient expert has truthfulness as a dominant strategy in an efficient mechanism with shared rewards.
\end{lem}

\begin{proof}
    by definition it maximizes the reward irrespective of other reports.
\end{proof}

\begin{lem}
	In the presense of a unilaterally sufficient expert our vcg-style mechanism and its scalings at most pays the sufficient expert.
\end{lem}

\begin{proof}
    the other reports never change 
\end{proof}


\begin{lem}
	In the presense of at least two unilaterally sufficient experts our vcg-style mechanism makes payments 0 in expectation in the full revelation BNE. 
\end{lem}

\begin{proof}
    Since one expert is sufficient, the other experts (sufficient or not) reports makes no change in the chosen action expected reward, and so the expected payoff is 0. This holds for each of the sufficient experts.
\end{proof}







% \begin{lem}
% 	necesssary: For truthfulnes to be dominant strategy for an expert, the expert must be unilaterally sufficient.
% \end{lem}
% \begin{proof}
%     By contradiction. If the expert is not unilaterally sufficient there exists signals $\hat{s}_{-i}$ the other experts may report such that $E[r|c_{s_i \cup s_{-i}}] > E[r|c_{i}] $
%\NDP{ This doesnt work further, since now I need to show there is some other report s_i that makes the expert better off, and there doesnt have to be in general.... so it is not necesary.}
% \end{proof}


% \begin{thm}
	
% \end{thm}

% \begin{proof}

% \end{proof}


\subsection{Noncompliance and Incentive Compatibility}

A natural question that arrises is how to handle the case where the action that is optimal given the reports (the chosen action under perfect compliance) is not the actual action taken by the subject. The three natural strategies from bandits with compliance awareness have their counterparts. Three natural strategies are:

\begin{itemize}
\item make payments irrespective. 
\item make the payment for the $\beta r_a$ but do not require the payment of $b_{i-1}$.
\item make no payment, and require no payment.
\end{itemize}

Only the first is incentive compatible. TODO: formalize. Sketch: a crucial property is that w separate bids and reports, this lets the reports be truthful while the bids are shaded (as is standard in common value seccond price auction). Further, it means that noncompliance (given the no defiers assumption) 
\DBA{maybe I'm missing something. But if the subject has a strong tendency to pick low-reward actions, then the experts are disincentivized from providing any advice at all, since they will likely receive negative payouts}
\NDP{The prior is over the noncompliance (what you are terming it the tendency to pick low actions here) }


If we do not require the payment, it can incentivize experts to report in such a way as to encourage non-compliance, since this would increase their payout. \DBA{example}


If we void the payment completely this can have the oposite effect, biasing experts away from reporting the \DBA{Is this paragraph dependent on agent's having a model of the subject's noncompliance? E.g. If subject's noncompliance is random (ignore advice with probability $p$ and then pick action uniformly), are the second and third options incentive compatible?}


for a cancer example; the chemiotherapy specialist might explain the likely side effects conditional on their knowledge of the specifics of the patient (the rapidly dropping cost of sequencing a genome means this) without needing to understand the relative value the patient places on discomfort relative to life lengthening, while the surgeon might explain the (again subject tot he specific characteristics of the subject) risks he foresees in the surgury (in contrast to the baseline risks of the populatin that gets the procude which is what cna be observed, a reasoable prior) for that patient, without needing to udnerstand the risk aversion of the patient which would be necesary for calculating their utility.

the subject (oracle style) can then be queried for their chosen action and expected utility for different subsets of the signals (for every expert we need to query what the action (and the expected payoff) would be without that experts signal having been reported)

contrast the information structure in the cancer example and its non separability 


\section{A bidding mechanism }

In many practical applications of interest, it might be that the signals can't be practically reported. For example, because while the expert knows something when they see it, they do not have a vocabulary to unambigously express it. 


If we replace the reports in the direct mechnaism by bids, and we allow the winner of the auction to pick the action, we have a mechanism that doesnt make any strong assumptions beyond that the agents understand the rules of the game.

For some information structures this still aggregates information well, for example:

\begin{lem}[specialist experts]
	if each expert knows the exact outcome conditonal on one action and knows he doesnt know what happens under other actions, and there is at least one expert that is informaed about each action.
\end{lem}

Note that this fails to satisfy the unilateraly sufficient expert requirement. Further, by the revelation priciple we cna create a direct mechanism that generates this outcome, and for this class of information structures is efficient (through clearly it will not be efficient for other information sturcutres, for example the one in the fully complemetary info example)

For other information structures it does not work, for exmaple 
\begin{eg}
	the classic example without separability that fails in the bayesian games so broadly (TODO Add cite) also fails here. 
\end{eg}

%\section{Summary}

\subsection{Interpreting bids}

the bids reflect the expected value of the mechanism choosing a particular action, not of that action being taken. \DBA{I'm confused. In previous section, ``each expert knows the exact outcome conditonal on one action'', and now its conditional on action being chosen, not taken. These sentences sentences seem to be at odds.} Example: if half are allways takers, the bid effectively waters down the true effect by half.
\DBA{So the bids made by experts depend on the expert's model of the subject's behavior?}

further, due to the winners curse, it is the expected effect conditional on having won the auction. 
\DBA{can you write down how expected conditional on having won is computed?}

\DBA{At this point, the interpretation of the bid has been qualified twice, and I'm lost}

\subsection{A sufficient separability condition for efficiency}

if each expert knows the value of a action the MSR and Void mechanism in the style of Hanson fail to be myopically incentive compatible when agents always follow the action whose price is maximal in the market (\cite{othman2010decision})


